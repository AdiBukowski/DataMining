\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[cp1250]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage{animate}
\newtheorem{theorem}{Twierdzenie}
\usepackage{mathtools}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne
<<ustawienia_globalne, echo=FALSE, warning=FALSE,results='hide',message=FALSE>>=
library(knitr)
library(xtable) #pakiet do tworzenia tabel w formacie LaTeX'a
library(animation)
library(ElemStatLearn)
library(MASS)
library(cluster)
library(ggplot2)
library(ROCR)
library(stats)
library(e1071)
library(neuralnet)
library(randomForest)
library(mlr)
library(kknn)

opts_chunk$set(fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=4,message=FALSE)
# UWAGA: w razie potrzeby mo¿na zmieniaæ te ustawienia w danym chunk'u!
@
  
  
  
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% strona tytulowa
\title{Filtrowanie spamu}
\author{Adrian Bukowski  Anna Miko³ajczyk}
\maketitle
\tableofcontents 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Wstêp oraz analiza opisowa}
Naszym zadaniem jest rozpoznanie czy dany email jest spamem czy nie. Mamy do czynienia z 57 zmiennymi spoœród których:
\begin{itemize}
\item 48 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego s³owa w mailu (za s³owo uznajemy dowolny ci¹g liter i cyfr)
\item 6 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego znaku w mailu 
\item 1 przyjmuje wartoœci dodatnie i oznacza œredni¹ d³ugoœæ nieprzerywanych ci¹gów wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza d³ugoœæ najd³u¿szego nieprzerwanego ci¹gu wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza ³¹czna iloœæ wielkich liter w mailu
\end{itemize}
Oprócz tego dane zawieraj¹ kolumnê spam/mail oznaczaj¹c¹ czy dany mail jest spamem. Mamy wiêc do czynienia z zadaniem klasyfikacji. Zbiór zawiera 4601 elementów. Przyjrzyjmy siê danym:
<<>>=
data("spam")
dim(spam)
X<-spam[,1:(dim(spam)[2]-1)]
y<-spam[,dim(spam)[2]]
@
SprawdŸmy czy dane s¹ dobrze wczytane:
<<>>=
sapply(X,class)
@
Jak widaæ zmienne s¹ zgodne z opisem. Zobaczmy czy nie wystêpuj¹ brakuj¹ce dane:
<<>>=
sum(is.na(X))
@
Nie mamy do czynienia z danymi brakuj¹cymy.

Podstawowe statystyki dla zmiennych objaœniaj¹cych:
<<>>=
summary(X)
@
Zobaczmy tak¿e jak wygl¹da kowiariancja zmiennych:
<<>>=
kowariancja <- cov(X)
heatmap(kowariancja)
@

Przyjrzyjmy siê tak¿e zmiennej objaœnianej:
<<>>=
class(y)
levels(y)
@
Jak widaæ jest to zmienna typu "factor" o dwóch poziomach - "email" i "spam".

Zobaczmy jak dziel¹ siê nasze dane ze wzglêdu na zmienn¹ obj¹snian¹:
<<>>=
tab<-table(y)
tab
as.matrix(tab)
data<-as.data.frame(tab)
colnames(data)<-c('type','freq')
ggplot(data, aes(x=as.factor(type), y=freq,fill=as.factor(type)))+geom_bar(stat = "identity")+ labs(x="", y='Ilosc') + theme(legend.position="none")
prop.table(tab)
@
Jak widaæ oko³o 60\% to emaile, a 40\% to spam.

W celu bardziej œwiadomej analizy dodajmy nazwy kolumn:
<<>>=
spamColNames <- c("word_freq_make", "word_freq_address", "word_freq_all", "word_freq_3d", 
    "word_freq_our", "word_freq_over", "word_freq_remove", "word_freq_internet", 
    "word_freq_order", "word_freq_mail", "word_freq_receive", "word_freq_will", 
    "word_freq_people", "word_freq_report", "word_freq_addresses", "word_freq_free", 
    "word_freq_business", "word_freq_email", "word_freq_you", "word_freq_credit", 
    "word_freq_your", "word_freq_font", "word_freq_000", "word_freq_money", 
    "word_freq_hp", "word_freq_hpl", "word_freq_george", "word_freq_650", "word_freq_lab", 
    "word_freq_labs", "word_freq_telnet", "word_freq_857", "word_freq_data", 
    "word_freq_415", "word_freq_85", "word_freq_technology", "word_freq_1999", 
    "word_freq_parts", "word_freq_pm", "word_freq_direct", "word_freq_cs", "word_freq_meeting", 
    "word_freq_original", "word_freq_project", "word_freq_re", "word_freq_edu", 
    "word_freq_table", "word_freq_conference", "char_freq_ch;", "char_freq_ch(", 
    "char_freq_ch[", "char_freq_ch!", "char_freq_ch$", "char_freq_ch#", "capital_run_length_average", 
    "capital_run_length_longest", "capital_run_length_total")
colnames(X)<-spamColNames
@

<<>>=
X.spam<-X[y=='spam',1:48]
X.email<-X[y=='email',1:48]
avg.X.spam <- sort(sapply(X.spam,mean),decreasing = TRUE)
avg.X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
avg.X.spam<-as.data.frame(avg.X.spam[1:10])
colnames(avg.X.spam)<-'avg_word_freq'
avg.X.email<-as.data.frame(avg.X.email[1:10])
colnames(avg.X.email)<-'avg_word_freq'
ggplot(avg.X.spam, aes(x=reorder(rownames(avg.X.spam),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(avg.X.spam, aes(x=reorder(rownames(avg.X.email),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1))
@

<<>>=
X.spam<-X[y=='spam', 49:54]
X.email<-X[y=='email', 49:54]
X.spam <- sort(sapply(X.spam, mean),decreasing = TRUE)
X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
X.spam <- cbind(X.spam,'spam')
X.email <- cbind(X.email,'email')
colnames(X.spam) <- c('avg.char.freq','type')
colnames(X.email) <- c('avg.char.freq','type')
X.char.freq <- rbind(X.spam,X.email)
X.char.freq <- cbind(rownames(X.char.freq),X.char.freq)
colnames(X.char.freq) <- c('char', 'avg.char.freq', 'type')
X.char.freq <- as.data.frame(X.char.freq) 
ggplot(X.char.freq, aes(x=as.factor(char), y = avg.char.freq, fill=type))+geom_bar(stat = "identity",position = "dodge")+ theme(axis.text.x = element_text(angle = 45, hjust = 1))
@

<<>>=
par(mfrow=c(1,3))
col.55<-as.data.frame(as.matrix(by(X[,55],y,mean)))
col.56<-as.data.frame(as.matrix(by(X[,56],y,mean)))
col.57<-as.data.frame(as.matrix(by(X[,57],y,mean)))
ggplot(col.55, aes(x=rownames(col.55),y=V1,fill=rownames(col.55)))+geom_bar(stat='identity') + theme(legend.position="none")
ggplot(col.56, aes(x=rownames(col.56),y=V1,fill=rownames(col.56)))+geom_bar(stat='identity') + theme(legend.position="none")
ggplot(col.57, aes(x=rownames(col.57),y=V1,fill=rownames(col.57)))+geom_bar(stat='identity') + theme(legend.position="none")
@

\section{Klasyfikacja}
Do klasyfikacji u¿yjemy pakietu mlr, który umo¿liwia wykorzystanie ró¿nych metod w szybki sposób. Naszym zadaniem jest klasyfikacja, zatem tworzymy zadanie klasyfikacji:
<<>>=
task <- makeClassifTask(data = spam, target = "spam")
@

<<echo=FALSE>>=
ROC<-function(pred.prob,true.labels){
  pred.ROCR <- ROCR::prediction(pred.prob, true.labels)
  perf.ROCR <- ROCR::performance(pred.ROCR, "tpr", "fpr")
  plot(perf.ROCR, print.cutoffs.at=seq(0.1,1,0.1), colorize=TRUE, lwd=2)
}
@
W kolejnych podroŸdzia³ach przyjrzymy siê jak kolejno klasyfikatory: Regresja Logistyczna, LDA, klasyfikator Naiwny Bayesa, Metoda kNN, Sieci Neuronowe, Lasy Losowe oraz SVM poradz¹ sobie z naszym zbiorem danych. Dla wszystkich klasyfikatorów oprócz sieci neuronowych zastosowana zostanie walidacja krzy¿owa z 5 podzbiorami. Jako miary dopasowania wybrane zosta³y dok³adnoœæ i AUC.
\subsection{Regresja Logistyczna}
Pierwszym modelem bêdzie regresja logistyczna:
<<>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.logistic$aggr
@
Jak widaæ ju¿ zwyk³a regresja logistyczna dobrze odró¿nia nasze dane - dok³adnoœæ wynosi prawie 93\%. Poni¿ej widzimy krzyw¹ ROC:
<<>>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

\subsection{LDA}
Kolejnym klasyfikatorem bêdzie metoda LDA:
<<>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.lda$aggr
@
Jak widaæ daje ona nieco gorsze efekty, uzyskuj¹c prawie 89\% skutecznoœæ. Poni¿ej przedstawiono krzyw¹ ROC:
<<>>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

\subsection{Klasyfikator Naiwny Baysa}
Nastêpnym klasyfikatorem bêdzie klasyfikator naiwny Bayesa:
<<>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.bayes$aggr
@
Klasyfikator Bayesa poradzi³ sobie z tym zadaniem najgorzej z dotychczasowych klasyfikatorów. Wykres ROC dla tego klasyfikatora prezentuje siê nastêpuj¹co:

<<>>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
Metoda k-Najbli¿szych S¹siadów jest nastêpn¹ z rozwa¿anych metod:
<<>>=
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob')
cv.knn <- crossval(learner = knn.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.knn$aggr
@
Uzyskuje ona dok³adnoœæ na poziomie nieca³ych 92\%, zatem wynik niewiele gorszy od regresji logistycznej. Poni¿ej widzimy wykres ROC:
<<>>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@


\subsection{Lasy losowe}
Przyjrzyjmy siê równie¿ klasyfikacji za pomoc¹ lasów losowych:
<<>>=
randForest.learner <- makeLearner("classif.randomForest", predict.type = 'prob')
cv.randForest <- crossval(learner = randForest.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.randForest$aggr
@
Otrzymujemy najlepszy dotychczas wynik - ponad 95\%. Ponadto AUC wynosi niemal¿e 100\%. Wykres krzywej ROC zaprezentowano poni¿ej: 

<<>>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

\subsection{Maszyna wektorów noœnych}
Ostatnim z rozwa¿anych klasyfikatorów jest SVM - maszyna wektorów noœnych:
<<>>=
svm.learner <- makeLearner("classif.svm", predict.type = 'prob')
cv.svm <- crossval(learner = svm.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.svm$aggr
@
Otrzymany wynik plasuje metode SVM dla naszych danych na 2 miejscu z wynikiem ponad 93\%. Wykres krzywej ROC przedstawiono poni¿ej:

<<>>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

\subsection{Porównanie}
<<results='asis'>>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych')
colnames(wyniki)<-c('Skutecznoœæ','AUC')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla danych "spam"')
print(xtab)
@

<<>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów:
<<>>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@

\section{Klasyfikacja z redukcj¹ wymiaru}
Spróbujmy teraz przeprowadziæ podobn¹ analizê z uprzednim zastosowaniem algorytmu PCA w celu redukcji wymiaru. 

<<>>=
X.pca <- prcomp(spam[,-dim(spam)[2]], retx = T)
@
ANALIZA PCA - WYBOR OPTYMALNEJ LICZBY n.
<<>>=
n<-7
X<-X.pca$x[,1:n]
spam.PCA<-cbind(X,spam$spam)
spam.PCA<-as.data.frame(spam.PCA)
colnames(spam.PCA)[dim(spam.PCA)[2]]<-'spam'
spam.PCA$spam<-as.factor(spam.PCA$spam)
levels(spam.PCA$spam)<-c('email','spam')
@

<<>>=
task <- makeClassifTask(data = spam.PCA, target = "spam")
@

\subsection{Regresja Logistyczna}
<<>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.logistic$aggr
@

<<>>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = logistic.learner, task = task)
@

\subsection{LDA}
<<>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.lda$aggr
@

<<>>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = lda.learner, task = task)
@

\subsection{Klasyfikator Naiwny Baysa}
<<>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.bayes$aggr
@

<<>>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = bayes.learner, task = task)
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
<<>>=
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob')
cv.knn <- crossval(learner = knn.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.knn$aggr
@

<<>>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = knn.learner, task = task)
@


\subsection{Lasy losowe}
<<>>=
randForest.learner <- makeLearner("classif.randomForest", predict.type = 'prob')
cv.randForest <- crossval(learner = randForest.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.randForest$aggr
@

<<>>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = randForest.learner, task = task)
@

\subsection{Maszyna wektorów noœnych}
<<>>=
svm.learner <- makeLearner("classif.svm", predict.type = 'prob')
cv.svm <- crossval(learner = svm.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc),show.info = F)
cv.svm$aggr
@

<<>>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

<<>>=
plotLearnerPrediction(learner = svm.learner, task = task)
@

\subsection{Porównanie}
<<results='asis'>>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych')
colnames(wyniki)<-c('Skutecznoœæ','AUC')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla sk³adowych g³ównych danych "spam" ')
print(xtab)
@

<<>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów:
<<>>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@



\section{Analiza skupieñ}
\subsection{K-means}
<<>>=
k <- 2
kmeans.k3 <- kmeans(X,centers=k,iter.max=10)
X.kmeans.clusters <- kmeans.k3$cluster
table(X.kmeans.clusters,y)
X.pca <- prcomp(X,retx=T)
X.pca.data <- X.pca$x[,1:2] 
X.pca.data.scaled<-scale(X.pca.data)
plot(X.pca.data.scaled[,1],X.pca.data.scaled[,2], col=as.factor(y), pch= as.numeric(X.kmeans.clusters))

k <- 3
kmeans.k3 <- kmeans(X,centers=k,iter.max=10)
X.kmeans <- kmeans.k3$cluster
table(X.kmeans,y)

@

\end{document}