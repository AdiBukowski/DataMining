\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[cp1250]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage{animate}
\newtheorem{theorem}{Twierdzenie}
\usepackage{mathtools}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne
<<ustawienia_globalne, echo=FALSE, warning=FALSE,results='hide',message=FALSE>>=
library(knitr)
library(xtable) #pakiet do tworzenia tabel w formacie LaTeX'a
library(animation)
library(ElemStatLearn)
library(MASS)
library(cluster)
library(ggplot2)
library(ROCR)
library(stats)
library(e1071)
library(neuralnet)
library(randomForest)
library(mlr)
library(kknn)
library(corrgram)
library(clValid)
library(mclust)
library(clv)
opts_chunk$set(fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=4,message=FALSE)
# UWAGA: w razie potrzeby mo¿na zmieniaæ te ustawienia w danym chunk'u!
@
  
  
  
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% strona tytulowa
\title{Filtrowanie spamu}
\author{Adrian Bukowski  Anna Miko³ajczyk}
\maketitle
\tableofcontents 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% MULTIPLOT %%% dzia³a jak par(mfrow=c(x,y)) dla ggplotów %%%
%%% wywo³anie: multiplot(wykres1, wykres2,. .. , wykresn, cols=liczba kolumn) %%%
<<multiplot, echo=FALSE, eval=TRUE>>=
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Wstêp oraz analiza opisowa}
Przedmiotem naszych rozwa¿añ s¹ dane dotycz¹ce zawartoœci 4601 wiadomoœci e-mail. Celem analiz jest filtrowanie spamu, tzn. rozró¿nienie spamu od po¿adanych wiadomoœci. Mamy do czynienia z 57 zmiennymi, spoœród których:
\begin{itemize}
\item 48 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego s³owa w mailu (za s³owo uznajemy dowolny ci¹g liter i cyfr)
\item 6 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego znaku w mailu 
\item 1 przyjmuje wartoœci dodatnie i oznacza œredni¹ d³ugoœæ nieprzerywanych ci¹gów wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza d³ugoœæ najd³u¿szego nieprzerwanego ci¹gu wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza ³¹czna iloœæ wielkich liter w mailu
\end{itemize}
Oprócz tego dane zawieraj¹ kolumnê spam/mail oznaczaj¹c¹ czy dany mail jest spamem. Mamy wiêc do czynienia z zadaniem klasyfikacji. Przyjrzyjmy siê danym.
<<>>=
data("spam")
dim(spam)
X<-spam[,1:(dim(spam)[2]-1)]
y<-spam[,dim(spam)[2]]
@
Przed wykonaniem analiz sprawdziliœmy czy dane s¹ dobrze wczytane, zmienne okaza³y siê zgodne z opisem. Upewniliœmy siê równie¿, ¿e nie wystêpuj¹ brakuj¹ce dane.
<<czy_dobrze_wczytane, echo=FALSE, eval=FALSE>>=
sapply(X,class)
@

<<brakujace_dane, echo=FALSE, eval=FALSE>>=
sum(is.na(X))
@
Na pocz¹tku analiz przyjrzeliœmy siê poszczególnym zmiennym, wyznaczaj¹c podstawowe statystyki opisowe (w zwi¹zku z du¿¹ iloœci¹ zmiennych nie umieszczamy ich w raporcie) i kowariancje pomiêdzy nimi (prezentujemy wynik w postaci tzw. heatmap, czyli mapy ciep³a).
<<pods_statystyki, echo=FALSE, eval=FALSE>>=
summary(X)
@

Na pocz¹tku analiz przyjrzeliœmy siê poszczególnym zmiennym, wyznaczaj¹c podstawowe statystyki opisowe (w zwi¹zku z du¿¹ iloœci¹ zmiennych nie umieszczamy ich w raporcie) i korelacje pomiêdzy nimi. Najpierw na zbiorze wszystkich zmiennych, jednak tak du¿y wykres korelacji okaza³ siê byæ bardzo nieczytelny, dlatego te¿ zrobiliœmy trzy osobne zestawienia dotycz¹ce 3 podgrup, kieruj¹c siê opisem poszczególnych zmiennych. Na poni¿szych wykresach im g³êbszy kolor, tym silniejsza korelacja miêdzy zmiennymi.
<<korelogramy, echo=FALSE, eval=TRUE, fig.height=6, fig.width=6, fig.cap="Korrelogram dla zmiennych zwi¹zanych z wystêpowaniem s³ów">>=
par(mfrow=c(2,1))
corrgram(X[,1:24], order=FALSE, lower.panel=panel.shade,
         upper.panel=panel.pie, text.panel=panel.txt)
@

<<korel2, echo=FALSE, eval=TRUE, fig.height=6, fig.width=6, fig.cap="Korrelogram dla zmiennych zwi¹zanych z wystêpowaniem s³ów C.D.">>=
corrgram(X[,25:48], order=FALSE, lower.panel=panel.shade,
         upper.panel=panel.pie, text.panel=panel.txt)
@

<<corelogramy2, echo=FALSE, eval=TRUE, fig.height=6, fig.width=6, fig.cap="Korrelogram zmiennych zwi¹zanych z wystêpowaniem znaków i wielkich liter">>=
corrgram(X[,49:57], order=FALSE, lower.panel=panel.shade,
         upper.panel=panel.pie, text.panel=panel.txt)
@
Analiza wieloczynnikowa pokazuje, ¿e prawie ¿adne zmienne nie s¹ ze sob¹ skorelowane. Pojawiaj¹ siê jednak pary, jak na przyk³ad A34 i A32, dla których korelacja przekracza nawet $75\%$. Zweryfikowaliœmy czy usuniêcie tych pojedynczych zmiennych wp³ywa istotnie na wyniki. Poniewa¿ nie zaobserwowaliœmy poprawy, postanowiliœmy analizowaæ kompletny zbiór danych "spam". 

Nastêpnie skupiliœmy sie na zmiennej objaœnianej
<<zm_objasniajaca, echo=TRUE, eval=TRUE>>=
class(y)
levels(y)
@
Jest to zmienna typu "factor" o dwóch poziomach - "email" i "spam".

W kolejnym kroku, zbadaliœmy jak dziel¹ siê dane, którymi dysponujemy, ze wzglêdu na zmienn¹ objaœnian¹. Rozk³ad mo¿emy obserwowaæ na poni¿szym wykresie s³upkowym.
<<podzial_wzgl_y, echo=FALSE, eval=TRUE, fig.cap="Rozk³ad wiadomoœci na spam i po¿¹dane e-maile">>=
tab<-table(y)
tab
as.matrix(tab)
data<-as.data.frame(tab)
colnames(data)<-c('type','freq')
ggplot(data, aes(x=as.factor(type), y=freq,fill=as.factor(type)))+geom_bar(stat = "identity")+ labs(x="", y='Ilosc') + theme(legend.position="none")
prop.table(tab)
@
Okaza³o siê, ¿e oko³o 60\% obserwacji stanowi¹ po¿¹dane e-maile, a 40\% spam. 

Posi³kuj¹c siê dokumentacj¹ danych, aby nasze analizy by³y bardziej œwiadome, dodaliœmy nazwy kolumn. 
<<nazwy_kolumn, echo=FALSE, eval=TRUE>>=
spamColNames <- c("word_freq_make", "word_freq_address", "word_freq_all", "word_freq_3d", 
    "word_freq_our", "word_freq_over", "word_freq_remove", "word_freq_internet", 
    "word_freq_order", "word_freq_mail", "word_freq_receive", "word_freq_will", 
    "word_freq_people", "word_freq_report", "word_freq_addresses", "word_freq_free", 
    "word_freq_business", "word_freq_email", "word_freq_you", "word_freq_credit", 
    "word_freq_your", "word_freq_font", "word_freq_000", "word_freq_money", 
    "word_freq_hp", "word_freq_hpl", "word_freq_george", "word_freq_650", "word_freq_lab", 
    "word_freq_labs", "word_freq_telnet", "word_freq_857", "word_freq_data", 
    "word_freq_415", "word_freq_85", "word_freq_technology", "word_freq_1999", 
    "word_freq_parts", "word_freq_pm", "word_freq_direct", "word_freq_cs", "word_freq_meeting", 
    "word_freq_original", "word_freq_project", "word_freq_re", "word_freq_edu", 
    "word_freq_table", "word_freq_conference", "char_freq_ch;", "char_freq_ch(", 
    "char_freq_ch[", "char_freq_ch!", "char_freq_ch$", "char_freq_ch#", "capital_run_length_average", 
    "capital_run_length_longest", "capital_run_length_total")
colnames(X)<-spamColNames
@
W celu wy³apania ró¿nic pomiêdzy obserwacjami które s¹ spamem, a tymi które nie s¹, podzieliliœmy ca³¹ próbkê na dwie roz³¹czne. Chcieliœmy równie¿ sprawdziæ czym wyró¿niaj¹ siê wiadomoœci bêd¹ce spamem, a czym pozosta³e.
Poni¿sze wykresy przedstawiaj¹, które s³owa pojawiaj¹ siê z najwiêksz¹ œredni¹ czêstotliwoœci¹ we wspomnianych grupach.
<<slowa_podzial, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=8, fig.cap="Najwiêksze œrednie czêstotliwoœci pojawiania siê s³ów wœród spamu i wiadomoœci po¿¹danych">>=
X.spam<-X[y=='spam',1:48]
X.email<-X[y=='email',1:48]
avg.X.spam <- sort(sapply(X.spam,mean),decreasing = TRUE)
avg.X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
avg.X.spam<-as.data.frame(avg.X.spam[1:10])
colnames(avg.X.spam)<-'avg_word_freq'
avg.X.email<-as.data.frame(avg.X.email[1:10])
colnames(avg.X.email)<-'avg_word_freq'
w1_spam <- ggplot(avg.X.spam, aes(x=reorder(rownames(avg.X.spam),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) +ggtitle("Spam")
w2_email <- ggplot(avg.X.email, aes(x=reorder(rownames(avg.X.email),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) +ggtitle("E-mail")
multiplot(w1_spam, w2_email, cols=2)
@
£atwo zauwa¿yæ, ¿e najczêœciej mamy do czynienia ze s³owem "you", jednak wystepuje ono w obu grupach, zatem prawdopodobnie, nie ró¿nicuje ich we w³aœciwy sposób. Drugie w kolejnoœci, jeœli chodzi o œredni procentowy udzia³ s³owa we wiadomoœci, w przypadku spamu, jest s³owo "your", a w przypadku e-maili s³owa "George" i "hp".
Z kolejnych wykresów, mo¿emy odczytaæ jakie znaki stanowi¹ œrednio najwiêkszy procentowy udzia³ w wiadomoœci, w przypadkach spamu i zwyk³ych e-maili.
<<znaki_podzial, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=6, fig.cap="Najwiêksze œrednie czêstotliwoœci pojawiania siê znaków w spamie i po¿¹danych wiadomoœciach">>=
X.spam<-X[y=='spam', 49:54]
X.email<-X[y=='email', 49:54]
X.spam <- sort(sapply(X.spam, mean),decreasing = TRUE)
X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
X.spam <- cbind(X.spam,'spam')
X.email <- cbind(X.email,'email')
colnames(X.spam) <- c('avg.char.freq','type')
colnames(X.email) <- c('avg.char.freq','type')
X.char.freq <- rbind(X.spam,X.email)
X.char.freq <- cbind(rownames(X.char.freq),X.char.freq)
colnames(X.char.freq) <- c('char', 'avg.char.freq', 'type')
X.char.freq <- as.data.frame(X.char.freq) 
ggplot(X.char.freq, aes(x=as.factor(char), y = avg.char.freq, fill=type)) + 
  geom_bar(stat = "identity",position = "dodge") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
Widzimy, ¿e œrednio w spamie, wiêkszy procentowy udzia³ maj¹ znaki !, \#, \$, a w e-mailach ), ], ;. Mo¿na przypuszczaæ, ¿e wystêpowanie znaków \$ i ] jest istotne w rozpoznawaniu spamu, poniewa¿ w ich przypadku obserwujemy najwiêksz¹ ró¿nicê pomiêdzy œrednim procentowym udzia³em w spamie i w e-mailu.
Koñcz¹c wstêpne analizy, zajêliœmy siê jeszcze 3 ostatnimi zmiennymi, czyli œredni¹ d³ugoœci¹ nieprzerwanych ci¹gów wielkich liter, d³ugoœci¹ najd³u¿szego nieprzerywanego ci¹gu wielkich liter oraz ³¹czn¹ iloœci¹ wielkich liter w mailu.
<<wielkie_litery_podzial, echo=FALSE, eval=TRUE, fig.height=3, fig.width=8, fig.cap="Analiza wielkich liter w spamie i w po¿¹danych wiadomoœciach", warning=FALSE>>=
par(mfrow=c(1,3))
col.55<-as.data.frame(as.matrix(by(X[,55],y,mean)))
col.56<-as.data.frame(as.matrix(by(X[,56],y,mean)))
col.57<-as.data.frame(as.matrix(by(X[,57],y,mean)))
w1<-ggplot(col.55, aes(x=rownames(col.55),y=V1,fill=rownames(col.55)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Sr. dl. ciagu wlk. liter")
w2<-ggplot(col.56, aes(x=rownames(col.56),y=V1,fill=rownames(col.56)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Najdluzszy ciag wlk. liter")
w3<-ggplot(col.57, aes(x=rownames(col.57),y=V1,fill=rownames(col.57)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Laczna ilosc")
multiplot(w1,w2,w3, cols=3)
@
Powy¿sze wykresy sugeruj¹, ¿e wielkie litery znacznie wiêksz¹ rolê odgrywaj¹ w spamie. Przyjrzyjmy siê histogramom czêstoœci wystêpowania niektórych s³ów:
<<fig.height=4,fig.width=8, fig.cap="Rozk³ad przyk³adowych zmiennych">>=
q1<-qplot(X$word_freq_you, geom="histogram") +
    xlab("Procentowy udzia³ s³owa 'you' w mailu")
q2<-qplot(X$word_freq_will, geom="histogram")+
    xlab("Procentowy udzia³ s³owa 'will' w mailu")
multiplot( q1,q2, cols=2)
@
Charakter rozk³adów jest dyskretno-ci¹g³y z atomem w 0. Dodatkowo dane nie przypominaj¹ rozk³adu normalnego i s¹ ciê¿koogonowe. Warto zatem rozwa¿yæ transformacjê logarytmiczn¹. Ze wzglêdu na wspomniane wartoœci zerowe rozwa¿ymy jednak transformacjê $\log (x+0.1)$.
<<fig.height=4,fig.width=8, fig.cap="Rozk³ad przyk³adowych zmiennych po transformacji">>=
q1<-qplot(log(X$word_freq_you+0.1), geom="histogram") +
    xlab("Logarytm z procentowego udzia³u s³owa 'you' w mailu")
q2<-qplot(log(X$word_freq_will+0.1), geom="histogram") +
    xlab("Logarytm z procentowego udzia³u s³owa 'will' w mailu")
multiplot( q1,q2, cols=2)
@
Oczywiœcie dalej mamy do czynienia z atomem w punkcie $\log (0.1)$, jednak pozosta³e dane du¿o bardziej przypominaj¹ rozk³ad normalny. Transformacjê zastosujemy do metod LDA i LR (w pozosta³ych metodach pogorsza³a ona wyniki).
Po wstêpnej analizie przechodzimy do bardziej z³o¿onych rozwa¿añ zwi¹zanych z postawionym problemem.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metody}
Projekt skupia siê na zagadnieniach klasyfikacji i analizy skupieñ na przyk³adzie zbioru danych "spam". Celem projektu jest porównanie skutecznoœci metod klasyfikacji oraz jakoœci metod analizy skupieñ. W raporcie rozpatrzyliœmy te same metody z uwzglêdnieniem redukcji wymiaru za pomoc¹ metody PCA. W przypadku klasyfikacji wykorzystaliœmy nastêpuj¹ce metody:
\begin{itemize}
\item Regresja Logistyczna
\item LDA 
\item Klasyfikator Naiwny Bayesa
\item Metoda k Najbli¿szych S¹siadów
\item Lasy Losowe
\item SVM
\item XGBoost
\end{itemize}
Do porównania skutecznoœci klasyfikacji wykorzystaliœmy wskaŸniki:
\begin{itemize}
\item Skutecznoœæ (accuracy)
\item ROC
\item AUC
\item Czu³oœæ 
\item Specyficznoœæ
\end{itemize}
Do analizy skupieñ zastosowaliœmy:
\begin{itemize}
\item k-Means
\item PAM
\item AGNES
\item DIANA
\end{itemize}
Do analizy jakoœci grupowania wykorzystaliœmy wskaŸniki zarówno wewnêtrzne jak i zewnêtrzne: 
\begin{itemize}
\item Silhouette
\item wskaŸnik Dunn'a
\item wskaŸnik Randa
\item wskaŸnik Jaccarda
\item wskaŸnik Fowlkesa-Mallowsa 
\end{itemize}


\section{Klasyfikacja}
Zajmiemy siê teraz zagadnieniem klasyfikacji. Wykorzystamy pakiet mlr, który umo¿liwia zastosowanie ró¿nych metod w szybki sposób. Zaczynamy od stworzenia zadania klasyfikacji. Dostrajanie parametróW i badanie skutecznoœci zostanie wykonane za pomoc¹ walidacji krzy¿owej na 80\% danych, a nastêpnie na pozosta³ych 20\% sprawdzimy uzyskan¹ skutecznoœæ.
<<zad_klasyf, echo=TRUE, eval=TRUE>>=
spam.log<-spam
spam.log[,-dim(spam)[2]]<-log(spam[,-dim(spam)[2]]+0.1)
smp<- sample(dim(spam)[1],dim(spam)[1]*0.2)
test.log<- spam.log[smp,]
train.log<-spam.log[-smp,]
test <-spam[smp,]
train<-spam[-smp,]
task.log <- makeClassifTask(data = train.log, target = "spam")
task<-makeClassifTask(data=train, target = "spam")
data("spam")
@
W kolejnym roku napisaliœmy funkcjê do rysowania krzywej ROC.
<<roc, echo=TRUE, eval=TRUE>>=
ROC<-function(pred.prob,true.labels){
  pred.ROCR <- ROCR::prediction(pred.prob, true.labels)
  perf.ROCR <- ROCR::performance(pred.ROCR, "tpr", "fpr")
  plot(perf.ROCR, print.cutoffs.at=seq(0.1,1,0.1), colorize=TRUE, lwd=2)
}
@
W kolejnych podrozdzia³ach wyznaczymy klasyfikatory za pomoc¹ regresji logistycznej (RL), LDA, klasyfikatora Naiwnego Bayes'a, metody kNN, lasów losowych, SVM oraz XGBoost. Dla wszystkich klasyfikatorów zastosowana zostanie walidacja krzy¿owa z 5 podzbiorami. W celu porównania dopasowania porównamy dok³adnoœæ i AUC.

\subsection{Regresja Logistyczna}
Zaczynamy od  jednej z najpopularniejszych metod klasyfikacji, czyli regresji logistycznej. Wykorzystamy dane po przekszta³ceniu.
<<RL, echo=TRUE, eval=TRUE, warning=FALSE>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task.log, iters = 5,
                        stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                        show.info = F)
cv.logistic$aggr
@
Jak widaæ ju¿ zwyk³a regresja logistyczna dobrze odró¿nia nasze dane - dok³adnoœæ wynosi prawie 94\%. Po rozwa¿eniu wszystkich metod, przedstawimy dla nich krzywe ROC na jednym wykresie.
<<RL_ROC, echo=FALSE, eval=FALSE, fig.cap="Regresja logistyczna: krzywa ROC">>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

\subsection{LDA}
Kolejnym klasyfikator otrzymamy za pomoc¹ metody LDA. Podobnie jak w regresjii logistycznej wykorzystamy dane po przekszta³ceniu.
<<LDA, echo=TRUE, eval=TRUE>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task.log, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                   show.info = F)
cv.lda$aggr
@
Otrzymujemy niewiele gorszy wynik ni¿ przy u¿yciu regresji logistycznej.
<<LDA_ROC, echo=FALSE, eval=FALSE, fig.cap="LDA: krzywa ROC">>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

\subsection{Klasyfikator Naiwny Baysa}
Nastêpnym klasyfikatorem bêdzie klasyfikator naiwny Bayesa.
<<kNB, echo=TRUE, eval=TRUE>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task, iters = 5,
                     stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                     show.info = F)
cv.bayes$aggr
@
Klasyfikator Bayesa poradzi³ sobie z tym zadaniem najgorzej z dotychczasowych klasyfikatorów.

<<kNB_ROC, echo=FALSE, eval=FALSE, fig.cap="Naiwny klasyfikator Bayes'a: krzywa ROC">>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
Metoda k-Najbli¿szych S¹siadów jest nastêpn¹ z rozwa¿anych metod. W celu doboru liczby s¹siadów wykorzystamy metodê 'Grid search' na siatce od 1 do 10 s¹siadów.
<<kNN, echo=TRUE, eval=TRUE>>=
knn_params <- makeParamSet(
  makeDiscreteParam("k", values = c(1,2,3,4,5,6,7,8,9,10))
)
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.kknn", task = task, resampling = rdesc,
  par.set = knn_params, control = ctrl)
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob', 
                           par.vals = tuned_params$x)
cv.knn <- crossval(learner = knn.learner, task = task, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                   show.info = F)
cv.knn$aggr
@
Algorytm wybra³ model z \Sexpr{tuned_params$x$k} s¹siadami. Uzyskuje ona dok³adnoœæ na poziomie nieca³ych 92\%, zatem wynik niewiele gorszy od regresji logistycznej. Poniewa¿ wykorzystaliœmy te same dane do strojenia parametru oraz ewaluacji modelu, powinniœmy zatem sprawdziæ jeszcze jak model radzi sobie na nowych danych (najlepiej wykorzystuj¹c walidacjê krzy¿ow¹), poniewa¿ jednak 'podwójna' walidacja krzy¿owa jest bardzo kosztowna obliczeniowo (zw³aszcza dla metod typu lasy losowe/xgboost/sieci neuronowe), zatem dla metody kNN jak i nastêpnych sprawdzimy skutecznoœæ na jednym zbiorze testowym.  
Wynik na zbiorze testowym:
<<echo=FALSE>>=
mod <- train(knn.learner, task= task)
test.pred<-predict(mod,newdata = test)
knn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
knn.test.acc
@

Jest on podobny do wyniku uzyskanego metod¹ walidacji krzy¿owej na zbiorze treningowym, co czyni model wiarygodnym.
<<kNN_ROC, echo=FALSE, eval=FALSE, fig.cap="k-NN: krzywa ROC">>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@


\subsection{Lasy losowe}
Przyjrzyjmy siê równie¿  klasyfikacji za pomoc¹ lasów losowych. W celu doboru parametrów: liczby drzew, liczby zmiennych branych pod uwagê przy ka¿dym podziale, maksymalnej liczby liœci i minimalnej liczby zmiennych w liœciu, wykorzystamy metodê 'Random search' z odpowiednimi przedzia³ami pocz¹tkowymi. 
<<LL, echo=TRUE, eval=TRUE>>=
randForest_params <- makeParamSet(
  makeIntegerParam("ntree", lower = 100, upper = 500),
  makeIntegerParam("mtry", lower = 1, upper = 10),
  makeIntegerParam("maxnodes", lower = 5, upper = 50),
  makeIntegerParam("nodesize", lower = 1, upper = 15)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.randomForest", task = task, 
                          resampling = rdesc, par.set = randForest_params, 
                          control = ctrl)

randForest.learner <- makeLearner("classif.randomForest", 
                                  predict.type = 'prob', 
                                  par.vals = tuned_params$x)
cv.randForest <- crossval(learner = randForest.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                          show.info = F)
cv.randForest$aggr
@
Po wybraniu odpowiednich parametrów model uzyska³ skutecznoœæ ponad 93\%. Zobaczmy jak wygl¹da wynik na zbiorze testowym:
<<>>=
mod <- train(randForest.learner, task= task)
test.pred<-predict(mod,newdata = test)
randForest.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
randForest.test.acc
@
Wynik na zbiorze testowym wynosi \Sexpr{randForest.test.acc}, zatem jest on podobny jak w zbiorze treningowym. Poni¿ej przedstawiono wykres krzywej ROC.
<<LL_ROC, echo=FALSE, eval=FALSE, fig.cap="Lasy losowe: krzywa ROC">>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

\subsection{Maszyna wektorów noœnych}
Kolejnym z rozwa¿anych klasyfikatorów jest SVM z j¹drem gaussowskim. W celu odpowiedniego dobrania parametrów $C$ i $\gamma$ zastosujemy metodê 'Random search', czyli losowe przeszukiwanie w którym podajemy odpowiedni zakres do przeszukania. 
<<SVM, echo=TRUE, eval=TRUE>>=
svm_params <- makeParamSet(
  makeNumericParam("C", lower = -1, upper = 10, trafo = function(x) 2^x),
  makeNumericParam("epsilon", lower = -1, upper = 10, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.ksvm", task = task, resampling = rdesc,
  par.set = svm_params, control = ctrl)
svm.learner <- setHyperPars(makeLearner("classif.ksvm", predict.type = 'prob'), 
                            par.vals = tuned_params$x)
cv.svm <- crossval(learner = svm.learner, task = task, iters = 5,
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                   show.info = F)
cv.svm$aggr
@
Otrzymaliœmy wynik ponad 93\%. Dla parametrów $C$ i $\gamma$ odpowiednio \Sexpr{tuned_params$x$C} i \Sexpr{tuned_params$x$epsilon}. Zobaczmy jaki wynik otrzymamy na zbiorze testowym:
<<>>=
mod <- train(svm.learner, task= task)
test.pred<-predict(mod,newdata = test)
svm.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
svm.test.acc
@

<<SVM_ROC, echo=FALSE, eval=FALSE, fig.cap="SVM: krzywa ROC">>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

\subsection{XGBoost}
Jednym z najskuteczniejszych algorytmów, wygrywaj¹cych w konkursach pozyskiwania wiedzy na stronach typu Kaggle jest znany algorytm XGBoost (eXtreme Gradient Boosting). Jest to przyk³ad algorytmu wykorzystuj¹cego boosting. Algorytm ze wzglêdu na z³o¿onoœæ posiada wiele hiperparametrów, które wybierzemy metod¹ 'Random search' podaj¹c tylko granice poszukiwañ.

<<>>=
xgb_params <- makeParamSet(
  makeIntegerParam("nrounds", lower = 100, upper = 500),
  makeIntegerParam("max_depth", lower = 1, upper = 10),
  makeNumericParam("eta", lower = .1, upper = .5),
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 3)
tuned_params <- tuneParams('classif.xgboost', task = task,
                           resampling = resample_desc,par.set = xgb_params,
control = control)
xgboost.learner <- makeLearner("classif.xgboost", predict.type = 'prob', 
                               par.vals = tuned_params$x)
cv.xgboost <- crossval(learner = xgboost.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), 
                       show.info = F)
cv.xgboost$aggr
@
Jeden z obecnie najskuteczniejszych algorytmów, podobnie na tym zbiorze uzyska³ bardzo dobry wynik ponad 95\%. Zobaczmy jaki wynik uzyska³ na zbiorze testowym.
<<>>=
mod <- train(xgboost.learner, task= task)
test.pred<-predict(mod,newdata = test)
xgboost.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
xgboost.test.acc
@

<<XGBoost_ROC, echo=FALSE, eval=FALSE, fig.cap="XGBoost: krzywa ROC">>=
ROC(cv.xgboost$pred$data[,4],cv.xgboost$pred$data[,2])
@
\subsection{Sieci neuronowe}
Ostatni¹ wœród metod klasyfikacji przedstawionych w projekcie s¹ sieci neuronowe. Charakteryzuj¹ siê one du¿¹ z³o¿onoœci¹ obliczeniow¹ i ma³¹ interpretowalnoœci¹, zazwyczaj jednak dobr¹ lub bardzo dobr¹ skutecznoœci¹.
<<>>=
nn_params <- makeParamSet(
  makeIntegerParam("size", lower = 5, upper = 10),
  makeNumericParam("decay", lower=0,upper=5)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 3)
nn_learner <- makeLearner("classif.nnet", predict.type = 'prob', trace=FALSE)
tuned_params <- tuneParams(nn_learner, task = task,resampling = resample_desc,par.set = nn_params, control = control)
nn_learner <- makeLearner("classif.nnet", predict.type = 'prob', par.vals = tuned_params$x)
nn_learner<-setHyperPars(nn_learner,trace=FALSE)
cv.nn <- crossval(learner = nn_learner, task = task, iters = 5, stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)

cv.nn$aggr
@

Zobaczmy jak dla optymalnych parametrów, tzn. \Sexpr{tuned_params$x$size} neuronów nasza sieæ sprawdzi siê na nowych danych.
<<>>=
mod <- train(nn_learner, task= task)
test.pred<-predict(mod,newdata = test)
nn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
nn.test.acc
@



\subsection{Porównanie}
<<porownanie_klasyf, echo=FALSE, eval=TRUE, results='asis', fig.cap="Skutecznoœæ metod klasyfikacji">>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr,cv.xgboost$aggr,cv.nn$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych','XGBoost','Sieci neuronowe')
colnames(wyniki)<-c('Skutecznoœæ','AUC', 'Czu³oœæ','Specyficznoœæ')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla danych "spam"')
print(xtab)
@
Najskuteczniejsz¹ metod¹ okaza³ siê XGBoost, jednak znacznie prostsze metody takie jak regresja logistyczna, która ponadto umo¿liwia interpretacjê modelu, daj¹ niemal¿e identyczne wyniki. Najmniej skuteczn¹ metod¹ jest klasyfikator naiwny Bayesa. 
<<roc_klasyf_razem, echo=FALSE, eval=TRUE>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
pred.xgboost<-getRRPredictions(cv.xgboost)
pred.nn<-getRRPredictions(cv.nn)

@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów.
<<por_ROC_klasyf, echo=FALSE, eval=TRUE, fig.width=8, fig.height=4.5, fig.cap="Porównanie krzywych ROC dla ró¿nych klasyfikatorów">>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm, xgboost = pred.xgboost, nnet = pred.nn), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@

\section{Redukcja wymiaru}
Poniewa¿ dysponujemy danymi z 58 zmiennymi, konieczna wydaje siê byæ redukcja wymiaru.

\subsection{PCA}
W tym celu wykorzystamy metodê PCA. Poni¿ej prezentujemy wykres osypiskowy i wykres skumulowanej wariancji, dziêki którym mo¿emy zaobserwowaæ jaki udzia³ w wyjaœnianiu zmiennoœci, maj¹ kolejne sk³adowe g³ówne. 
<<pca, echo=FALSE, eval=TRUE, fig.cap="Analiza zmiennoœci wyjaœnianej przez kolejne sk³adowe g³ówne", fig.width=8, fig.height=9>>=
#redukcja wymiaru
#pca
n<-dim(spam)[1]
spam.pca<-spam[,1:57]
spam.po.pca <- prcomp(spam.pca, retx=T, center=T, scale.=T) 
#print("Skladowe glowne:")
#print(spam.po.pca$rotation[,10])
#summary(spam.po.pca)

#analiza zmiennoœci wyjaœnianej przez sk³adowe g³ówne
wariancja <- ( spam.po.pca$sdev ^2)/sum(spam.po.pca$sdev^2) 
avg_var<-mean(wariancja)
#for(i in 1:57){
 # if(wariancja[i] < avg_var)
 # {print(i) 
 #}
#}
wariancja.narast <- cumsum(wariancja)
par(mfrow=c(2,1))
barplot(wariancja, ylim=c(0, 0.12))
abline(a=avg_var, b=0, col="red", lwd=2, lty=2)
text(x=50, y=avg_var+0.002, label = "œrednia wariancja", col="red")
barplot(wariancja.narast)
abline(a=0.25, b=0, col="red", lwd=2, lty=2)
text(x=2, y=0.27, label = "25%", col="red")
abline(a=0.5, b=0, col="orange", lwd=2, lty=2)
text(x=2, y=0.52, label = "50%", col="orange")
abline(a=0.75, b=0, col="green", lwd=2, lty=2)
text(x=2, y=0.77, label = "75%", col="green")
par(mfrow=c(2,1))
@
Przy tak du¿ej iloœci zmiennych, stawianie sobie progu np. 90\% wyjaœnianej zmiennoœci, zaprowadzi³o by nas do dalszego rozwa¿anie niemal¿e wszystkich zmiennych. Jednak nie taki by³ nasz cel, musimy zatem w inny sposób ustaliæ, ile sk³adowych g³ównych braæ pod uwagê. W tym celu wyznaczyliœmy wartoœæ œredni¹ wariancji i zaobserwowaliœmy, ¿e ka¿da z 20 pierwszych sk³adowych g³ównych, wyjaœnia wiêcej ni¿ œrednia wartoœæ zmiennoœci. Jednak weryfikuj¹c ten wynik, wykorzystuj¹c ocenê wizualn¹, ³atwo zauwa¿yæ, ¿e w przypadku sk³adowych 12-20 jest to niewielka ró¿nica, zatem rozs¹dnym wyborem wydaje siê byæ 11 sk³adowych g³ównych.

Pierwsze dwie sk³adowe g³ówne wyjaœniaj¹ zaledwie nieco ponad 17\% zmiennoœci. Poni¿ej prezentujemy wykres rozrzutu, w przestrzeni tych dwóch sk³adowych. 
<<pca_PCA1_PCA2, echo=FALSE, eval=TRUE, fig.cap="Wykres rozrzutu w przestrzeni dwóch pierwszych sk³adowych g³ównych">>=
#wizual.
plot(spam.po.pca$x[,1], spam.po.pca$x[,2], col=as.factor(y))
@



\section{Klasyfikacja z redukcj¹ wymiaru}
Spróbujmy teraz przeprowadziæ podobn¹ analizê z uprzednim zastosowaniem algorytmu PCA w celu redukcji wymiaru. Do dalszych analiz wybieramy 11 sk³adowych g³ównych. Porównamy wyniki wskaŸników takich jak w poprzednim roŸdziale, to zanczy skutecznoœci, AUC, czu³oœci i specyficznoœci. Po dobraniu parametrów do niektórych metod, sprawdzona zostanie skutecznoœæ na zbiorze testowym w celu porównania do zbioru treningowego. Dla ka¿dej metody zostan¹ przedstawione graficznie granice podzia³u dla pierwszych dwóch sk³adowych g³ównych.

<<red_pca, echo=FALSE, eval=TRUE>>=
X.pca <- prcomp(spam[,-dim(spam)[2]], retx = T)
@

<<red_pca2, echo=FALSE, eval=TRUE, warning=FALSE>>=
data('spam')
n<-11
X<-X.pca$x[,1:n]
spam.PCA<-cbind(X,spam$spam)
spam.PCA<-as.data.frame(spam.PCA)
colnames(spam.PCA)[dim(spam.PCA)[2]]<-'spam'
spam.PCA$spam<-as.factor(spam.PCA$spam)
levels(spam.PCA$spam)<-c('email','spam')
@


<<red_zad_klasyf, echo=TRUE, eval=TRUE>>=
smp<- sample(dim(spam.PCA)[1],dim(spam.PCA)[1]*0.2)
test <-spam.PCA[smp,]
train<-spam.PCA[-smp,]
task<-makeClassifTask(data=train, target = "spam")
@

\subsection{Regresja Logistyczna}
<<red_RL, echo=FALSE, eval=TRUE, warning=FALSE>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task, iters = 5,
                        stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.logistic$aggr
@

<<red_RL_ROC, echo=FALSE, eval=FALSE, fig.cap="RL po PCA: krzywa ROC", warning=FALSE>>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

<<red_RL_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ RL po PCA", warning=FALSE>>=
plotLearnerPrediction(learner = logistic.learner, task = task)
@

\subsection{LDA}
<<red_lda, echo=FALSE, eval=TRUE>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc,tpr,tnr),show.info = F)
cv.lda$aggr
@

<<red_lda_roc, echo=FALSE,eval=FALSE, fig.cap="LDA po PCA: krzywa ROC">>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

<<red_lda_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ LDA po PCA">>=
plotLearnerPrediction(learner = lda.learner, task = task)
@

\subsection{Klasyfikator Naiwny Bayesa}
<<red_knb, echo=FALSE, eval=TRUE>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc,tpr,tnr),show.info = F)
cv.bayes$aggr
@

<<red_knb_roc, echo=FALSE, eval=FALSE, fig.cap="KNB po PCA: krzywa ROC">>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

<<red_knb_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikator Naiwny Bayes'a po PCA">>=
plotLearnerPrediction(learner = bayes.learner, task = task)
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
<<red_knn, echo=FALSE, eval=TRUE>>=
knn_params <- makeParamSet(
  makeDiscreteParam("k", values = c(1,2,3,4,5,6,7,8,9,10))
)
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.kknn", task = task, resampling = rdesc,
  par.set = knn_params, control = ctrl)
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob', par.vals = tuned_params$x)
cv.knn <- crossval(learner = knn.learner, task = task, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.knn$aggr
@


<<>>=
mod <- train(knn.learner, task= task)
test.pred<-predict(mod,newdata = test)
knn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
knn.test.acc
@

<<red_knn_roc, echo=FALSE, eval=FALSE, fig.cap="kNN po PCA: krzywa ROC">>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@

<<red_knn_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ kNN po PCA">>=
plotLearnerPrediction(learner = knn.learner, task = task)
@


\subsection{Lasy losowe}
<<red_LL, echo=FALSE, eval=TRUE, warning=FALSE>>=
randForest_params <- makeParamSet(
  makeIntegerParam("ntree", lower = 100, upper = 500),
  makeIntegerParam("mtry", lower = 1, upper = 10),
  makeIntegerParam("maxnodes", lower = 5, upper = 50),
  makeIntegerParam("nodesize", lower = 1, upper = 15)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.randomForest", task = task, resampling = rdesc,
  par.set = randForest_params, control = ctrl)
randForest.learner <- makeLearner("classif.randomForest", predict.type = 'prob', par.vals = tuned_params$x)
cv.randForest <- crossval(learner = randForest.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.randForest$aggr
@

<<warning=FALSE>>=
mod <- train(randForest.learner, task= task)
test.pred<-predict(mod,newdata = test)
randForest.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
randForest.test.acc
@

<<red_RF_ROC, echo=FALSE, eval=FALSE, warning=FALSE, fig.cap="RF po PCA: krzywa ROC">>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

<<red_RF_klas, echo=FALSE, eval=TRUE, warning=FALSE, fig.cap="Las losowy po PCA">>=
plotLearnerPrediction(learner = randForest.learner, task = task)
@

\subsection{Maszyna wektorów noœnych}
<<red_svm, echo=FALSE, eval=TRUE>>=
svm_params <- makeParamSet(
  makeNumericParam("C", lower = -1, upper = 10, trafo = function(x) 2^x),
  makeNumericParam("epsilon", lower = -1, upper = 10, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.ksvm", task = task, resampling = rdesc,
  par.set = svm_params, control = ctrl)
svm.learner <- setHyperPars(makeLearner("classif.ksvm", predict.type = 'prob'), par.vals = tuned_params$x)
cv.svm <- crossval(learner = svm.learner, task = task, iters = 5,
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.svm$aggr
@


<<echo=FALSE>>=
mod <- train(svm.learner, task= task)
test.pred<-predict(mod,newdata = test)
svm.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
svm.test.acc
@

<<red_svm_roc, echo=FALSE, eval=FALSE, fig.cap="SVM po PCA: krzywa ROC">>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

<<red_svm_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ SVM po PCA">>=
plotLearnerPrediction(learner = svm.learner, task = task)
@
\subsection{XGBoost}
<<echo=FALSE>>=
xgb_params <- makeParamSet(
  makeIntegerParam("nrounds", lower = 100, upper = 500),
  makeIntegerParam("max_depth", lower = 1, upper = 10),
  makeNumericParam("eta", lower = .1, upper = .5),
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 5)
tuned_params <- tuneParams('classif.xgboost', task = task,resampling = resample_desc,par.set = xgb_params,
control = control)
xgboost.learner <- makeLearner("classif.xgboost", predict.type = 'prob', par.vals = tuned_params$x)
cv.xgboost <- crossval(learner = xgboost.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.xgboost$aggr
@

<<echo=FALSE>>=
mod <- train(xgboost.learner, task= task)
test.pred<-predict(mod,newdata = test)
xgboost.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
xgboost.test.acc
@

<<echo=FALSE, eval=FALSE, fig.cap="XGBoost: krzywa ROC">>=
ROC(cv.xgboost$pred$data[,4],cv.xgboost$pred$data[,2])
@

<<echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ SVM po PCA">>=
plotLearnerPrediction(learner = xgboost.learner, task = task)
@
\subsection{Sieci neuronowe}
<<echo=FALSE>>=
nn_params <- makeParamSet(
  makeIntegerParam("size", lower = 5, upper = 10),
  makeNumericParam("decay", lower=0,upper=5)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 3)
nn_learner <- makeLearner("classif.nnet", predict.type = 'prob', trace=FALSE)
tuned_params <- tuneParams(nn_learner, task = task,resampling = resample_desc,par.set = nn_params, control = control)
nn_learner <- makeLearner("classif.nnet", predict.type = 'prob', par.vals = tuned_params$x)
nn_learner<-setHyperPars(nn_learner,trace=FALSE)
cv.nn <- crossval(learner = nn_learner, task = task, iters = 5, stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)

cv.nn$aggr
@


<<>>=
mod <- train(nn_learner, task= task)
test.pred<-predict(mod,newdata = test)
nn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
nn.test.acc
@



<<echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja za pomoc¹ sieci neuronowych po PCA">>=
plotLearnerPrediction(learner = nn_learner, task = task)
@
\subsection{Porównanie}
<<red_por_klas, echo=FALSE, eval=TRUE, results='asis', fig.cap="Porównanie klasyfikatorów (po PCA)">>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr,cv.xgboost$aggr, cv.nn$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych','XGBoost','Sieci neuronowe')
colnames(wyniki)<-c('Skutecznoœæ','AUC','Czu³oœæ','Specyficznoœæ')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla sk³adowych g³ównych danych "spam" ')
print(xtab)
@
Tym razem wyraŸniej widaæ przewagê z³o¿onoœci algorytmu XGBoost nad prostrzymi metodami np. Regresji Logistycznej. Skutecznoœæ metody LDA wyraŸnie spad³a, natomiast pozosta³e metody zaliczy³y oko³o 4-5\% spadek skutecznoœci. 
<<red_pred, echo=FALSE, eval=TRUE>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
pred.xgboost<-getRRPredictions(cv.xgboost)
pred.xgboost<-getRRPredictions(cv.nn)
@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów:
<<red_por_roc, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=8, fig.cap="Porównanie krzywych ROC dla ró¿nych klasyfikatorów (po PCA)">>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm, xgboost=pred.xgboost, nnet= pred.nn), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@

Podobnie tym razem, bazuj¹c na mierze dok³adnoœci i auc, mo¿emy stwierdziæ, ¿e najlepiej poradzi³a sobie metoda lasów losowych.

\section{Analiza skupieñ}
Za³ó¿my na chwilê, ¿e nie wiemy jak sklasyfikowane s¹ obserwacje, którymi dysponujemy, tzn. nie wiemy czy s¹ spamem, czy nie. Usuwamy z danych kolumnê typu factor, wskazuj¹c¹ na ten podzia³. Wykorzystamy poznane metody klasteryzacji, maj¹ce na celu grupowanie danych w skupienia obiektów jak najbardziej do siebie podobnych, co wi¹¿e siê z rozpoznaniem struktury danych. Rozwa¿ymy metody grupuj¹ce, jak k-means i PAM oraz metody hierarchiczne, tj. AGNES i DIANA. W przypadku metody AGNES rozwa¿ymy 3 metody ³¹czenia skupieñ: "average", "single" i "complete". Macierze niepodobieñstw bêd¹ bazowa³y na odleg³oœci euklidesowej. Nie wykonujemy skalowania danych, poniewa¿ wariancja zmiennych jest jednorodna i taka operacja mog³aby pogorszyæ wyniki. Na koniec ocenimy jakoœæ grupowania.
\subsection{Metody grupuj¹ce}
\subsubsection{K-means}
Poniewa¿ dysponujemy wy³¹cznie zmiennymi iloœciowymi, mo¿emy œmia³o zastosowaæ metodê k-means. Poni¿esz przedstawiamy rezultat w przyk³adowej przestrzeni dwóch zmiennych.
<<start_an_sk, echo=FALSE, eval=TRUE, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ k-means (w przek³adowej przestrzeni dwóch zmiennych)">>=
spam.cechy <- spam[,1:57] # Usuwamy etykietki klas
spam.etykietki.rzeczywiste <- spam[,58]

k <- 2
kmeans.k2 <- kmeans(spam.cechy, centers=k, iter.max=20)
spam.etykietki.kmeans <- kmeans.k2$cluster

plot(spam.cechy$A.55, spam.cechy$A.57, col=spam.etykietki.kmeans,
     pch=as.numeric(spam.etykietki.rzeczywiste))
#points( kmeans.k2$centers[,c("A.23","A.6")],pch=16, cex=1.5, col=1:2)

@
\subsubsection{PAM}
Wypróbujemy równie¿ nieco bardziej z³o¿on¹ metodê PAM. Poni¿ej prezentujemy wykres podzia³u na klastry oraz œredni¹ szerokoœæ  silhouette.
<<pam, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=6, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ PAM">>=
#PAM
spam.pam<-spam[,1:57]
mac.niepod<-as.matrix(daisy(spam.pam))
spam.pam2 <- pam(x = mac.niepod, diss=TRUE, k=2)
etykietki <- spam.pam2$clustering
plot(spam.pam2, col=etykietki, metric="euclidian")
# summary(spam.pam2)
#  rozmiar(size), maksymalna i œrednia wartoœæ niepodobieñstwa (max_diss,av_diss),
#  œrednica (diameter), separacja  (separation)
# które obiekty s¹ centrami skupisk : CentraSkupisk.nazwy <- Cars93.pam3$medoids
@
Obserwuj¹c powy¿szy wykres mo¿emy zaobserwowaæ, ¿e otrzymaliœmy skupienia, o wyraŸnie ró¿nych liczbach obserwacji. Przypomnijmy, ¿e nasz zbiór sk³ada siê w ok. 60 \% z maili i ok. 40\% ze spamu, dlatego tak nierówne klastry, jakie otrzymaliœmy za pomoc¹ metody PAM, na pierwszy rzut oka, wydaj¹ siê nieodpowiednie, byæ mo¿e metoda PAM wykry³a inn¹ zale¿noœæ w danych.
<<clusplot, echo=FALSE, eval=TRUE, fig.cap="Wizualizacja wyników analizy skupieñ z wykorzystaniem PCA">>=
spam.CechyLiczbowe <- spam[,names(unlist(lapply(spam, FUN=function(x) if(is.numeric(x)) "numeric" else NULL)))]
spam.numeric.pam2 <- pam(spam.CechyLiczbowe, k=2, metric="euclidean")
clusplot(spam.numeric.pam2, color=FALSE, col.clus="yellow", col.p="red", plotchar=TRUE, shade=TRUE) #clusplot, z PCA

#jeszcze nie wiem jak oprócz kszta³tów rozró¿niæ kolory miêdzy klastrami :()
@
Przejdziemy teraz do drugiej grupy metod analizy skupieñ.
\subsection{Metody chierarchiczne}
Podstawow¹ wad¹ metod grupuj¹cych jest skutecznoœæ wykrywanie skupieñ wypuk³ych, metody chierarchiczne nie posiadaj¹ tej wady. Rozwa¿ymy dwa warianty: metodê aglomeracyjn¹ AGNES i metodê rozdzielania DIANA. Wyniki spróbujemy zwizualizowaæ za pomoc¹ wykresów typu 'bannerplot', dendrogramy w przypadku tak du¿ej iloœci danych, s¹ ca³kowicie nieczytelne.

<<AS_chierarch, echo=FALSE, eval=TRUE, fig.width=8, fig.height=7, fig.cap="AGNES i DIANA: wykresy typu 'banner'">>=
spam.scale<-spam[,1:57]
spam.MacNiepodob<-daisy(spam) #przygotowujemy macierz podobieñstw/odmiennosci
spam.agnes.avg <- agnes(x=spam.MacNiepodob,diss=TRUE,method="average")
spam.agnes.single <- agnes(x=spam.MacNiepodob,diss=TRUE,method="single")
spam.agnes.complete <- agnes(x=spam.MacNiepodob,diss=TRUE,method="complete")
spam.diana <- diana(x=spam.MacNiepodob,diss=TRUE)
par(mfrow=c(2,2))
plot(spam.agnes.avg, which.plot=1, main="AGNES: average linkage")
plot(spam.agnes.single, which.plot=1, main="AGNES: single linkage")
plot(spam.agnes.complete, which.plot=1, main="AGNES: complete linkage")
plot(spam.diana, which.plot=1, main="DIANA")
par(mfrow=c(1,1))
@
Widzimy, ¿e metody "average" and "single" poradzi³y sobie lepiej od pozosta³ych.

\subsubsection{WskaŸniki wewnêtrzne}
W kolejnym kroku dokonamy analizy jakoœci grupowania, odwo³uj¹c siê wy³¹cznie do w³asnoœci zawartych w danych. WeŸmiemy pod uwagê m. in. takie w³asnoœci jak: zwartoœæ, spójnoœæ czy separacja przestrzenna. Pos³u¿ymy siê wskaŸnikami Silhouette i Dunn'a.
WskaŸnik silhouette bierze pod uwagê zwartoœæ klastrów i separacjê przestrzenn¹, poni¿ej prezentujemy wykres œredniej wartoœci silhouette dla ca³ej partycji w przypadku podzia³u na $k=2, \dots, 6$ klastrów.
<<tot_internal, echo=FALSE, eval=TRUE, warning=FALSE, fig.cap="WskaŸniki wewnêtrzne: silhouette">>=
mac_pod<-daisy(spam.cechy)
############### silhuette ###################
# kmeans
cl2.kmeans <- kmeans(spam.cechy, centers=2)
cl3.kmeans <- kmeans(spam.cechy, centers=3)
cl4.kmeans <- kmeans(spam.cechy, centers=4)
cl5.kmeans <- kmeans(spam.cechy, centers=5)
cl6.kmeans <- kmeans(spam.cechy, centers=6)

sil.k2.kmeans <- silhouette(cl2.kmeans$cluster, mac_pod)
sil.k3.kmeans <- silhouette(cl3.kmeans$cluster, mac_pod)
sil.k4.kmeans <- silhouette(cl4.kmeans$cluster, mac_pod)
sil.k5.kmeans <- silhouette(cl5.kmeans$cluster, mac_pod)
sil.k6.kmeans <- silhouette(cl6.kmeans$cluster, mac_pod)

# pam
cl2.pam <- pam(spam.cechy, k=2)
cl3.pam <- pam(spam.cechy, k=3)
cl4.pam <- pam(spam.cechy, k=4)
cl5.pam <- pam(spam.cechy, k=5)
cl6.pam <- pam(spam.cechy, k=6)

sil.k2.pam <- silhouette(cl2.pam, mac_pod)
sil.k3.pam <- silhouette(cl3.pam, mac_pod)
sil.k4.pam <- silhouette(cl4.pam, mac_pod)
sil.k5.pam <- silhouette(cl5.pam, mac_pod)
sil.k6.pam <- silhouette(cl6.pam, mac_pod)

#agnes
agnes_spam<-agnes(spam.cechy, method="average")
cl2.agnes <- cutree(agnes_spam, k=2)
cl3.agnes <- cutree(agnes_spam, k=3)
cl4.agnes <- cutree(agnes_spam, k=4)
cl5.agnes <- cutree(agnes_spam, k=5)
cl6.agnes <- cutree(agnes_spam, k=6)

sil.k2.agnes <- silhouette(cl2.agnes, mac_pod)
sil.k3.agnes <- silhouette(cl3.agnes, mac_pod)
sil.k4.agnes <- silhouette(cl4.agnes, mac_pod)
sil.k5.agnes <- silhouette(cl5.agnes, mac_pod)
sil.k6.agnes <- silhouette(cl6.agnes, mac_pod)

#agnes1
agnes_spamS<-agnes(spam.cechy, method="single")
cl2.agnesS <- cutree(agnes_spamS, k=2)
cl3.agnesS <- cutree(agnes_spamS, k=3)
cl4.agnesS <- cutree(agnes_spamS, k=4)
cl5.agnesS <- cutree(agnes_spamS, k=5)
cl6.agnesS <- cutree(agnes_spamS, k=6)

sil.k2.agnesS <- silhouette(cl2.agnesS, mac_pod)
sil.k3.agnesS <- silhouette(cl3.agnesS, mac_pod)
sil.k4.agnesS <- silhouette(cl4.agnesS, mac_pod)
sil.k5.agnesS <- silhouette(cl5.agnesS, mac_pod)
sil.k6.agnesS <- silhouette(cl6.agnesS, mac_pod)

#agnes2
agnes_spamC<-agnes(spam.cechy, method="complete")
cl2.agnesC <- cutree(agnes_spamC, k=2)
cl3.agnesC <- cutree(agnes_spamC, k=3)
cl4.agnesC <- cutree(agnes_spamC, k=4)
cl5.agnesC <- cutree(agnes_spamC, k=5)
cl6.agnesC <- cutree(agnes_spamC, k=6)

sil.k2.agnesC <- silhouette(cl2.agnesC, mac_pod)
sil.k3.agnesC <- silhouette(cl3.agnesC, mac_pod)
sil.k4.agnesC <- silhouette(cl4.agnesC, mac_pod)
sil.k5.agnesC <- silhouette(cl5.agnesC, mac_pod)
sil.k6.agnesC <- silhouette(cl6.agnesC, mac_pod)


# diana
diana_spam<- diana(spam.cechy)
cl2.diana <- cutree(diana_spam, k=2)
cl3.diana <- cutree(diana_spam, k=3)
cl4.diana <- cutree(diana_spam, k=4)
cl5.diana <- cutree(diana_spam, k=5)
cl6.diana <- cutree(diana_spam, k=6)

sil.k2.diana <- silhouette(cl2.diana, mac_pod)
sil.k3.diana <- silhouette(cl3.diana, mac_pod)
sil.k4.diana <- silhouette(cl4.diana, mac_pod)
sil.k5.diana <- silhouette(cl5.diana, mac_pod)
sil.k6.diana <- silhouette(cl6.diana, mac_pod)

#summary(sil.k2)$clus.avg.widths[[1]]
#summary(sil.k3)$clus.avg.widths[[1]]
#summary(sil.k4)$clus.avg.widths[[1]]
#summary(sil.k5)$clus.avg.widths[[1]]
#summary(sil.k6)$clus.avg.widths[[1]]
#summary(sil.k2)$clus.avg.widths[[2]]
#summary(sil.k3)$clus.avg.widths[[2]]
#summary(sil.k4)$clus.avg.widths[[2]]
#summary(sil.k5)$clus.avg.widths[[2]]
#summary(sil.k6)$clus.avg.widths[[2]]

plot(c(2:6), c(
summary(sil.k2.kmeans)$si.summary[[4]],
summary(sil.k3.kmeans)$si.summary[[4]],
summary(sil.k4.kmeans)$si.summary[[4]],
summary(sil.k5.kmeans)$si.summary[[4]],
summary(sil.k6.kmeans)$si.summary[[4]]), xlab="Silhouette", ylab="Liczba klastrów", ylim=c(0.5, 1), type='b', pch=8, col="hotpink4", lwd=2, main="Silhouette")
lines( c(2:6),
c(summary(sil.k2.pam)$si.summary[[4]],
summary(sil.k3.pam)$si.summary[[4]],
summary(sil.k4.pam)$si.summary[[4]],
summary(sil.k5.pam)$si.summary[[4]],
summary(sil.k6.pam)$si.summary[[4]]), type='b', pch=9, col="pink", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnes)$si.summary[[4]],
summary(sil.k3.agnes)$si.summary[[4]],
summary(sil.k4.agnes)$si.summary[[4]],
summary(sil.k5.agnes)$si.summary[[4]],
summary(sil.k6.agnes)$si.summary[[4]]), type='b', pch=10, col="royalblue", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnesS)$si.summary[[4]],
summary(sil.k3.agnesS)$si.summary[[4]],
summary(sil.k4.agnesS)$si.summary[[4]],
summary(sil.k5.agnesS)$si.summary[[4]],
summary(sil.k6.agnesS)$si.summary[[4]]), type='b', pch=12, col="grey", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnesC)$si.summary[[4]],
summary(sil.k3.agnesC)$si.summary[[4]],
summary(sil.k4.agnesC)$si.summary[[4]],
summary(sil.k5.agnesC)$si.summary[[4]],
summary(sil.k6.agnesC)$si.summary[[4]]), type='b', pch=13, col="black", lwd=2)
lines( c(2:6),
c(summary(sil.k2.diana)$si.summary[[4]],
summary(sil.k3.diana)$si.summary[[4]],
summary(sil.k4.diana)$si.summary[[4]],
summary(sil.k5.diana)$si.summary[[4]],
summary(sil.k6.diana)$si.summary[[4]]), type='b', pch=11, col="orchid", lwd=2)
legend("bottomleft", c("kmeans", "pam", "agnes_a", "agnes_s", "agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue", "grey", "black", "orchid"), pch=c(8,9,10,12, 13,11), cex=0.7, title="Legenda")
@
Nietrudno zauwa¿yæ, ¿e w przypadku ka¿dej z metod miara silhouette osi¹ga najwiêksz¹ wartoœæ w przypadku podzia³u na 2 skupienia. Jak¹ kolejn¹ miarê jakoœci grupowania rozwa¿ymy wskaŸnik Dunn'a, przyjmuj¹cy wartoœci dodatnie, im wiêksza jego wartoœæ,  tym lepsza jakoœæ. Poni¿szy wykres przedstawia wartoœci wskaŸnika Dunn'a dla poszczególnych metod w przypadku grupowania na od $2$ do $6$ klastrów. 
<<dunn, echo=FALSE, eval=TRUE, warning=FALSE, fig.cap="WskaŸniki wewnêtrzne: wsk. Dunn'a">>=
### WSKANIK DUNN'A ###
plot ( c(2:6), c(dunn(distance=as.matrix(mac_pod), cl2.kmeans$cluster),
dunn(as.matrix(mac_pod), cl3.kmeans$cluster),
dunn(as.matrix(mac_pod), cl4.kmeans$cluster),
dunn(as.matrix(mac_pod), cl5.kmeans$cluster),
dunn(as.matrix(mac_pod), cl6.kmeans$cluster)), main="WskaŸnik Dunn'a", ylim=c(0, 1), xlab="WskaŸnik Dunn'a", ylab="Liczba klastrów", type='b', lwd=2, pch=8, col="hotpink4")
lines( c(2:6),
c(dunn(distance=as.matrix(mac_pod), cl2.pam$clustering),
dunn(as.matrix(mac_pod), cl3.pam$clustering),
dunn(as.matrix(mac_pod), cl4.pam$clustering),
dunn(as.matrix(mac_pod), cl5.pam$clustering),
dunn(as.matrix(mac_pod), cl6.pam$clustering)), type='b', pch=9, lwd=2, col="pink")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnes),
dunn(as.matrix(mac_pod), cl3.agnes),
dunn(as.matrix(mac_pod), cl4.agnes),
dunn(as.matrix(mac_pod), cl5.agnes),
dunn(as.matrix(mac_pod), cl6.agnes)), type='b', lwd=2, pch=10, col="royalblue")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnesS),
dunn(as.matrix(mac_pod), cl3.agnesS),
dunn(as.matrix(mac_pod), cl4.agnesS),
dunn(as.matrix(mac_pod), cl5.agnesS),
dunn(as.matrix(mac_pod), cl6.agnesS)), type='b', lwd=2, pch=12, col="grey")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnesC),
dunn(as.matrix(mac_pod), cl3.agnesC),
dunn(as.matrix(mac_pod), cl4.agnesC),
dunn(as.matrix(mac_pod), cl5.agnesC),
dunn(as.matrix(mac_pod), cl6.agnesC)), type='b', lwd=2, pch=13, col="black")
lines( c(2:6),
c(dunn(distance=as.matrix(mac_pod), cl2.diana),
dunn(as.matrix(mac_pod), cl3.diana),
dunn(as.matrix(mac_pod), cl4.diana),
dunn(as.matrix(mac_pod), cl5.diana),
dunn(as.matrix(mac_pod), cl6.diana)), type='b', lwd=2, pch=11, col="orchid")
legend("topright", c("kmeans", "pam", "agnes_a","agnes_s","agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue","grey","black", "orchid"), pch=c(8,9,10,12,13,11), cex=0.7, title="Legenda")
@
Wartoœci wskaŸników Dunn'a s¹ bardzo odmienne. W przypadku metod chierarchicznych: AGNES i DIANY wskaŸnik ten sugeruje odpowiednio podzia³y na 3 i 4 klastry. Wartoœci wskaŸnika Dunn'a dla k-means i PAM s¹ tak ma³e, ¿e nie jest mo¿liwy odczyt bezpoœrednio z wykresu, dlatego zawarliœmy wartoœci w poni¿szej tabelce, gdzie agnesa oznacza AGNES z wykorzystaniem metody ³¹czenia "average", agnesS z wykorzystaniem ³¹czenia "single" a agnesc z wykorzystaniem ³¹czenia "complete".
<<dunn_tab, echo=FALSE, eval=TRUE, warning=FALSE, results='asis'>>=
w4<-c(dunn(distance=as.matrix(mac_pod), cl2.diana),
dunn(as.matrix(mac_pod), cl3.diana),
dunn(as.matrix(mac_pod), cl4.diana),
dunn(as.matrix(mac_pod), cl5.diana),
dunn(as.matrix(mac_pod), cl6.diana))
w3<-c(dunn(distance=as.matrix(mac_pod), cl2.agnes),
dunn(as.matrix(mac_pod), cl3.agnes),
dunn(as.matrix(mac_pod), cl4.agnes),
dunn(as.matrix(mac_pod), cl5.agnes),
dunn(as.matrix(mac_pod), cl6.agnes))
w3S<-c(dunn(distance=as.matrix(mac_pod), cl2.agnesS),
dunn(as.matrix(mac_pod), cl3.agnesS),
dunn(as.matrix(mac_pod), cl4.agnesS),
dunn(as.matrix(mac_pod), cl5.agnesS),
dunn(as.matrix(mac_pod), cl6.agnesS))
w3C<-c(dunn(distance=as.matrix(mac_pod), cl2.agnesC),
dunn(as.matrix(mac_pod), cl3.agnesC),
dunn(as.matrix(mac_pod), cl4.agnesC),
dunn(as.matrix(mac_pod), cl5.agnesC),
dunn(as.matrix(mac_pod), cl6.agnesC))
w2<-c(dunn(distance=as.matrix(mac_pod), cl2.pam$clustering),
dunn(as.matrix(mac_pod), cl3.pam$clustering),
dunn(as.matrix(mac_pod), cl4.pam$clustering),
dunn(as.matrix(mac_pod), cl5.pam$clustering),
dunn(as.matrix(mac_pod), cl6.pam$clustering))
w1<-c(dunn(distance=as.matrix(mac_pod), cl2.kmeans$cluster),
dunn(as.matrix(mac_pod), cl3.kmeans$cluster),
dunn(as.matrix(mac_pod), cl4.kmeans$cluster),
dunn(as.matrix(mac_pod), cl5.kmeans$cluster),
dunn(as.matrix(mac_pod), cl6.kmeans$cluster))
w<-c("k-means", "pam", "agnes_a","agnes_S", "agnes_C", "diana")
k<-c("2","3", "4","5", "6")
macierz<-rbind(w1,w2,w3, w3S, w3C,w4)
dimnames(macierz)=list(w,k)
tabela3<-xtable(macierz, digits=5, row.names=FALSE, caption="WskaŸnik Dunn'a", label="tabela:tabela3")

# align(tabela)<-"|c|c|c|c|c|c|"
print(tabela3, type="latex", table.placement="H", sanitize.text.function = function(x) {x})
@
Widzimy, ¿e w przypadku metod k-means i pam, wskaŸnik Dunn'a identyfikuje grupowanie najlepszej jakoœci dla 2 klastrów.


\subsubsection{WskaŸniki zewnêtrzne}
W kolejnym kroku zajmiemy siê analiz¹ wskaŸników zewnêtrznych, czyli takich, które wykorzystuj¹ informacjê o rzeczywistej przynale¿noœci do skupieñ. Rozwa¿ymy 4 metody i przypadek 2 klastrów. Poni¿sza tabelka przedstawia iloœæ maili i spamu przyporz¹dkowych do dwóch klastrów i \% par, która w³aœciwie znalaz³y siê w osobnych skupieniach.
<<zgodnosc_partycji2, echo=FALSE, eval=TRUE, results='asis'>>=

# porównanie wynikow grupowania z rzeczywist¹ przynaleznoscia do klas
tab.spam.kmeans <- table(kmeans.k2$cluster, spam$spam)
#matchClasses(tab.spam.kmeans, method="exact")

tab.spam.pam <- table(spam.pam2$clustering, spam$spam)
#matchClasses(tab.spam.pam, method="exact")

tab.spam.agnes <- table(cl2.agnes, spam$spam)
#matchClasses(tab.spam.agnes, method="exact")

tab.spam.agnesS <- table(cl2.agnesS, spam$spam)
tab.spam.agnesC <- table(cl2.agnesC, spam$spam)

tab.spam.diana <- table(cl2.diana, spam$spam)
#matchClasses(tab.spam.diana, method="exact")


w2<-c(tab.spam.pam[1],tab.spam.pam[2],tab.spam.pam[3],tab.spam.pam[4], 100*( tab.spam.pam[1]+tab.spam.pam[4] )/4601)
w1<-c(tab.spam.kmeans[1],tab.spam.kmeans[2],tab.spam.kmeans[3],tab.spam.kmeans[4], 100*( tab.spam.kmeans[1]+tab.spam.kmeans[4] )/4601)
w3<-c(tab.spam.agnes[1],tab.spam.agnes[2],tab.spam.agnes[3],tab.spam.agnes[4], 100*( tab.spam.agnes[1]+tab.spam.agnes[4] )/4601)
w3S<-c(tab.spam.agnesS[1],tab.spam.agnesS[2],tab.spam.agnesS[3],tab.spam.agnesS[4], 100*( tab.spam.agnesS[1]+tab.spam.agnesS[4] )/4601)
w3C<-c(tab.spam.agnesC[1],tab.spam.agnesC[2],tab.spam.agnesC[3],tab.spam.agnesC[4], 100*( tab.spam.agnesC[1]+tab.spam.agnesC[4] )/4601)
w4<-c(tab.spam.diana[1],tab.spam.diana[2],tab.spam.diana[3],tab.spam.diana[4], 100*( tab.spam.diana[1]+tab.spam.diana[4] )/4601)

w<-c("k-means", "pam", "agnes_a", "agnes_s", "agnes_c", "diana")
k<-c("e-mail_1","e-mail_2", "spam_1","spam_2", "matched(proc)")
macierz<-rbind(w1,w2,w3, w3S, w3C ,w4)
dimnames(macierz)=list(w,k)
tabela<-xtable(macierz, digits=0, row.names=FALSE, caption="Dopasowanie klas", label="tabela:tabela")

# align(tabela)<-"|c|c|c|c|c|c|"
print(tabela, type="latex", table.placement="H", sanitize.text.function = function(x) {x})


@
W przypadku k-means i PAM otrzymujemy najwiêkszy procent "pasuj¹cych" par (ostatnia kolumna). Analizuj¹c dalej wskaŸniki zgodnoœci partycji, przechodzimy do wyznaczenia wskaŸników Randa, Jaccarda i Fowlkesa-Mallowsa. 
WskaŸnik Randa przyjmuje wartoœci od $0$ do $1$ i im wiêksza jego wartoœæ tym lepsza zgodnoœæ partycji. Poni¿ej prezentujemy wykres wartoœci wskaŸnika Randa dla rozwa¿anych metod zastosowanych do grupowania na od $2$ do $6$ skupieñ.
<<wsk_zew_Rand_jaccard_fawkl, echo=FALSE, eval=TRUE, fig.cap="WskaŸniki zewnêtrzne: wsk. Randa">>=

pred2.kmeans <- as.integer(cl2.kmeans$cluster)
pred3.kmeans <- as.integer(cl3.kmeans$cluster)
pred4.kmeans <- as.integer(cl4.kmeans$cluster)
pred5.kmeans <- as.integer(cl5.kmeans$cluster)
pred6.kmeans <- as.integer(cl6.kmeans$cluster)

pred2.pam <- as.integer(cl2.pam$clustering)
pred3.pam <- as.integer(cl3.pam$clustering)
pred4.pam <- as.integer(cl4.pam$clustering)
pred5.pam <- as.integer(cl5.pam$clustering)
pred6.pam <- as.integer(cl6.pam$clustering)

pred2.agnes <- as.integer(cl2.agnes)
pred3.agnes <- as.integer(cl3.agnes)
pred4.agnes <- as.integer(cl4.agnes)
pred5.agnes <- as.integer(cl5.agnes)
pred6.agnes <- as.integer(cl6.agnes)

pred2.agnesS <- as.integer(cl2.agnesS)
pred3.agnesS <- as.integer(cl3.agnesS)
pred4.agnesS <- as.integer(cl4.agnesS)
pred5.agnesS <- as.integer(cl5.agnesS)
pred6.agnesS <- as.integer(cl6.agnesS)

pred2.agnesC <- as.integer(cl2.agnesC)
pred3.agnesC <- as.integer(cl3.agnesC)
pred4.agnesC <- as.integer(cl4.agnesC)
pred5.agnesC <- as.integer(cl5.agnesC)
pred6.agnesC <- as.integer(cl6.agnesC)

pred2.diana <- as.integer(cl2.diana)
pred3.diana <- as.integer(cl3.diana)
pred4.diana <- as.integer(cl4.diana)
pred5.diana <- as.integer(cl5.diana)
pred6.diana <- as.integer(cl6.diana)

std2kmeans <- std.ext(pred2.kmeans, as.integer(spam$spam))
rand2kmeans <- clv.Rand(std2kmeans)
jaccard2kmeans <- clv.Jaccard(std2kmeans)
folk.mal2kmeans <- clv.Folkes.Mallows(std2kmeans)

std3kmeans <- std.ext(pred3.kmeans, as.integer(spam$spam))
rand3kmeans <- clv.Rand(std3kmeans)
jaccard3kmeans <- clv.Jaccard(std3kmeans)
folk.mal3kmeans <- clv.Folkes.Mallows(std3kmeans)

std4kmeans <- std.ext(pred4.kmeans, as.integer(spam$spam))
rand4kmeans <- clv.Rand(std4kmeans)
jaccard4kmeans <- clv.Jaccard(std4kmeans)
folk.mal4kmeans <- clv.Folkes.Mallows(std4kmeans)

std5kmeans <- std.ext(pred5.kmeans, as.integer(spam$spam))
rand5kmeans <- clv.Rand(std5kmeans)
jaccard5kmeans <- clv.Jaccard(std5kmeans)
folk.mal5kmeans <- clv.Folkes.Mallows(std5kmeans)

std6kmeans <- std.ext(pred6.kmeans, as.integer(spam$spam))
rand6kmeans <- clv.Rand(std6kmeans)
jaccard6kmeans <- clv.Jaccard(std6kmeans)
folk.mal6kmeans <- clv.Folkes.Mallows(std6kmeans)

###

std2pam <- std.ext(pred2.pam, as.integer(spam$spam))
rand2pam <- clv.Rand(std2pam)
jaccard2pam <- clv.Jaccard(std2pam)
folk.mal2pam <- clv.Folkes.Mallows(std2pam)

std3pam <- std.ext(pred3.pam, as.integer(spam$spam))
rand3pam <- clv.Rand(std3pam)
jaccard3pam <- clv.Jaccard(std3pam)
folk.mal3pam <- clv.Folkes.Mallows(std3pam)

std4pam <- std.ext(pred4.pam, as.integer(spam$spam))
rand4pam <- clv.Rand(std4pam)
jaccard4pam <- clv.Jaccard(std4pam)
folk.mal4pam <- clv.Folkes.Mallows(std4pam)

std5pam <- std.ext(pred5.pam, as.integer(spam$spam))
rand5pam <- clv.Rand(std5pam)
jaccard5pam <- clv.Jaccard(std5pam)
folk.mal5pam <- clv.Folkes.Mallows(std5pam)

std6pam <- std.ext(pred6.pam, as.integer(spam$spam))
rand6pam <- clv.Rand(std6pam)
jaccard6pam <- clv.Jaccard(std6pam)
folk.mal6pam <- clv.Folkes.Mallows(std6pam)

## 

std2agnes <- std.ext(pred2.agnes, as.integer(spam$spam))
rand2agnes <- clv.Rand(std2agnes)
jaccard2agnes <- clv.Jaccard(std2agnes)
folk.mal2agnes <- clv.Folkes.Mallows(std2agnes)

std3agnes <- std.ext(pred3.agnes, as.integer(spam$spam))
rand3agnes <- clv.Rand(std3agnes)
jaccard3agnes <- clv.Jaccard(std3agnes)
folk.mal3agnes <- clv.Folkes.Mallows(std3agnes)

std4agnes <- std.ext(pred4.agnes, as.integer(spam$spam))
rand4agnes <- clv.Rand(std4agnes)
jaccard4agnes <- clv.Jaccard(std4agnes)
folk.mal4agnes <- clv.Folkes.Mallows(std4agnes)

std5agnes <- std.ext(pred5.agnes, as.integer(spam$spam))
rand5agnes <- clv.Rand(std5agnes)
jaccard5agnes <- clv.Jaccard(std5agnes)
folk.mal5agnes <- clv.Folkes.Mallows(std5agnes)

std6agnes <- std.ext(pred6.agnes, as.integer(spam$spam))
rand6agnes <- clv.Rand(std6agnes)
jaccard6agnes <- clv.Jaccard(std6agnes)
folk.mal6agnes <- clv.Folkes.Mallows(std6agnes)

## 

std2agnesS <- std.ext(pred2.agnesS, as.integer(spam$spam))
rand2agnesS <- clv.Rand(std2agnesS)
jaccard2agnesS <- clv.Jaccard(std2agnesS)
folk.mal2agnesS <- clv.Folkes.Mallows(std2agnesS)

std3agnesS <- std.ext(pred3.agnesS, as.integer(spam$spam))
rand3agnesS <- clv.Rand(std3agnesS)
jaccard3agnesS <- clv.Jaccard(std3agnesS)
folk.mal3agnesS <- clv.Folkes.Mallows(std3agnesS)

std4agnesS <- std.ext(pred4.agnesS, as.integer(spam$spam))
rand4agnesS <- clv.Rand(std4agnesS)
jaccard4agnesS <- clv.Jaccard(std4agnesS)
folk.mal4agnesS <- clv.Folkes.Mallows(std4agnesS)

std5agnesS <- std.ext(pred5.agnesS, as.integer(spam$spam))
rand5agnesS <- clv.Rand(std5agnesS)
jaccard5agnesS <- clv.Jaccard(std5agnesS)
folk.mal5agnesS <- clv.Folkes.Mallows(std5agnesS)

std6agnesS <- std.ext(pred6.agnesS, as.integer(spam$spam))
rand6agnesS <- clv.Rand(std6agnesS)
jaccard6agnesS <- clv.Jaccard(std6agnesS)
folk.mal6agnesS <- clv.Folkes.Mallows(std6agnesS)

## 

std2agnesC <- std.ext(pred2.agnesC, as.integer(spam$spam))
rand2agnesC <- clv.Rand(std2agnesC)
jaccard2agnesC <- clv.Jaccard(std2agnesC)
folk.mal2agnesC <- clv.Folkes.Mallows(std2agnesC)

std3agnesC <- std.ext(pred3.agnesC, as.integer(spam$spam))
rand3agnesC <- clv.Rand(std3agnesC)
jaccard3agnesC <- clv.Jaccard(std3agnesC)
folk.mal3agnesC <- clv.Folkes.Mallows(std3agnesC)

std4agnesC <- std.ext(pred4.agnesC, as.integer(spam$spam))
rand4agnesC <- clv.Rand(std4agnesC)
jaccard4agnesC <- clv.Jaccard(std4agnesC)
folk.mal4agnesC <- clv.Folkes.Mallows(std4agnesC)

std5agnesC <- std.ext(pred5.agnesC, as.integer(spam$spam))
rand5agnesC <- clv.Rand(std5agnesC)
jaccard5agnesC <- clv.Jaccard(std5agnesC)
folk.mal5agnesC <- clv.Folkes.Mallows(std5agnesC)

std6agnesC <- std.ext(pred6.agnesC, as.integer(spam$spam))
rand6agnesC <- clv.Rand(std6agnesC)
jaccard6agnesC <- clv.Jaccard(std6agnesC)
folk.mal6agnesC <- clv.Folkes.Mallows(std6agnesC)


std2diana <- std.ext(pred2.diana, as.integer(spam$spam))
rand2diana <- clv.Rand(std2diana)
jaccard2diana <- clv.Jaccard(std2diana)
folk.mal2diana <- clv.Folkes.Mallows(std2diana)

std3diana <- std.ext(pred3.diana, as.integer(spam$spam))
rand3diana <- clv.Rand(std3diana)
jaccard3diana <- clv.Jaccard(std3diana)
folk.mal3diana <- clv.Folkes.Mallows(std3diana)

std4diana <- std.ext(pred4.diana, as.integer(spam$spam))
rand4diana <- clv.Rand(std4diana)
jaccard4diana <- clv.Jaccard(std4diana)
folk.mal4diana <- clv.Folkes.Mallows(std4diana)

std5diana <- std.ext(pred5.diana, as.integer(spam$spam))
rand5diana <- clv.Rand(std5diana)
jaccard5diana <- clv.Jaccard(std5diana)
folk.mal5diana <- clv.Folkes.Mallows(std5diana)

std6diana <- std.ext(pred6.diana, as.integer(spam$spam))
rand6diana <- clv.Rand(std6diana)
jaccard6diana <- clv.Jaccard(std6diana)
folk.mal6diana <- clv.Folkes.Mallows(std6diana)

plot(c(2:6), c(rand2kmeans, rand3kmeans, rand4kmeans, rand5kmeans, rand6kmeans), type='b', lwd=2, col="hotpink4", main="Rand", pch=8, ylim=c(0.5, 0.6), xlab="Liczba klastrów", ylab="Rand")
lines(c(2:6), c(rand2pam, rand3pam, rand4pam, rand5pam, rand6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(rand2agnes, rand3agnes, rand4agnes, rand5agnes, rand6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(rand2agnesS, rand3agnesS, rand4agnesS, rand5agnesS, rand6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(rand2agnesC, rand3agnesC, rand4agnesC, rand5agnesC, rand6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(rand2diana, rand3diana, rand4diana, rand5diana, rand6diana), type='b', lwd=2, col="orchid", pch=11)
legend("topleft", c("kmeans", "pam", "agnes_a", "agnes_s","agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue","grey","black", "orchid"), pch=c(8,9,10,12,13,11), cex=0.7, title="Legenda")

@
WskaŸnik Randa osi¹ga wiêksze wartoœci, zgodnie z wykresem, przy klasteryzacji na $3,4$ lub $5$ skupieñ. Kierowanie siê tylko jednym wskaŸnikiem, mog³oby nas zaprowadziæ do wyci¹gniêcia b³êdnych wniosków dotycz¹cych wewnêtrznej struktory danych, dlatego przeanalizujemy inne miary. Poni¿ej przedstawiamy wykres wskaŸników Jaccarda i Fowlkesa-Mallowsa.
<<wsk_zew_cd, echo=FALSE, eval=TRUE, fig.width=8, fig.height=4.5, fig.cap="WskaŸniki zewnêtrzne: Jaccarda i Fowlkesa-Mallowsa">>=
par(mfrow=c(1,2))
plot(c(2:6), c(jaccard2kmeans, jaccard3kmeans, jaccard4kmeans, jaccard5kmeans, jaccard6kmeans), type='b', lwd=2, col="hotpink4", main="Jaccard", pch=8, ylim=c(0.3, 0.55), xlab="Liczba klastrów", ylab="Jaccard")
lines(c(2:6), c(jaccard2pam, jaccard3pam, jaccard4pam, jaccard5pam, jaccard6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(jaccard2agnes, jaccard3agnes, jaccard4agnes, jaccard5agnes, jaccard6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(jaccard2agnesS, jaccard3agnesS, jaccard4agnesS, jaccard5agnesS, jaccard6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(jaccard2agnesC, jaccard3agnesC, jaccard4agnesC, jaccard5agnesC, jaccard6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(jaccard2diana, jaccard3diana, jaccard4diana, jaccard5diana, jaccard6diana), type='b', lwd=2, col="orchid", pch=11)
legend("bottomleft", c("kmeans", "pam", "agnes_a", "agnes_s", "agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue","grey","black", "orchid"), pch=c(8,9,10,12, 13, 11), cex=0.7, title="Legenda")

plot(c(2:6), c(folk.mal2kmeans, folk.mal3kmeans, folk.mal4kmeans, folk.mal5kmeans, folk.mal6kmeans), type='b', lwd=2, col="hotpink4", main="folk.mal", pch=8, ylim=c(0.45, 0.75), xlab="Liczba klastrów", ylab="Fowlkes-Mallows")
lines(c(2:6), c(folk.mal2pam, folk.mal3pam, folk.mal4pam, folk.mal5pam, folk.mal6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(folk.mal2agnes, folk.mal3agnes, folk.mal4agnes, folk.mal5agnes, folk.mal6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(folk.mal2agnesS, folk.mal3agnesS, folk.mal4agnesS, folk.mal5agnesS, folk.mal6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(folk.mal2agnesC, folk.mal3agnesC, folk.mal4agnesC, folk.mal5agnesC, folk.mal6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(folk.mal2diana, folk.mal3diana, folk.mal4diana, folk.mal5diana, folk.mal6diana), type='b', lwd=2, col="orchid", pch=11)
legend("bottomleft", c("kmeans", "pam", "agnes_a","agnes_s", "agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue", "orchid"), pch=c(8,9,10, 12, 13,11), cex=0.7, title="Legenda")
par(mfrow=c(1,1))
@
Zarówno wskaŸnik Jaccarda, jak i Fowlkesa-Mallowska przyjmuj¹ najwiêksze wartoœci przy klasteryzacji na 2 skupienia, w szczególnoœci istotne ró¿nice obserwujemy w przypadku k-means i PAM.

%Na koniec zbadamy problem analizy skupieñ z uwzglêdnieniem redukcji wymiary metod¹ PCA. Zgodnie z wyjaœnieniem przy problemie %klasteryzacji, bierzemy pod uwagê 11 pierwszych sk³adowych g³ównych.

%\section{Analiza skupieñ z redukcj¹ wymiaru}
<<start_an_sk_PCA, echo=FALSE, eval=FALSE, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ k-means (w przek³adowej przestrzeni dwóch zmiennych)">>=

spam.cechy.PCA <- spam.PCA[,1:11]
spam.etykietki.rzeczywiste <- spam$spam

k <- 2
kmeans.k2 <- kmeans(spam.cechy.PCA, centers=k, iter.max=20)
spam.etykietki.kmeans <- kmeans.k2$cluster


@

<<pam_PCA, echo=FALSE, eval=FALSE, fig.height=4.5, fig.width=6, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ PAM">>=
#PAM
spam.pam<-spam.PCA[,1:11]
mac.niepod<-as.matrix(daisy(spam.pam))
spam.pam2 <- pam(x = mac.niepod, diss=TRUE, k=2)
etykietki <- spam.pam2$clustering
plot(spam.pam2, col=etykietki, metric="euclidian")

clusplot(spam.numeric.pam2, color=FALSE, col.clus="yellow", col.p="red", plotchar=TRUE, shade=TRUE) #clusplot, z PCA

@

<<AS_chierarch_PCA, echo=FALSE, eval=FALSE, fig.height=7, fig.width=8, fig.cap="AGNES i DIANA: wykres typu 'banner'">>=
spam<-spam.PCA[,1:11]
spam.MacNiepodob<-daisy(spam) #przygotowujemy macierz podobieñstw/odmiennosci
spam.agnes.avg <- agnes(x=spam.MacNiepodob,diss=TRUE,method="average") #wykorzystujemy optymaln¹ metodê  average linkage
spam.agnes.single <- agnes(x=spam.MacNiepodob,diss=TRUE,method="single")
spam.agnes.complete <- agnes(x=spam.MacNiepodob,diss=TRUE,method="complete")
spam.diana <- diana(x=spam.MacNiepodob,diss=TRUE)
par(mfrow=c(2,2))
plot(spam.agnes.avg, which.plot=1, main="AGNES: average linkage")
plot(spam.agnes.single, which.plot=1, main="AGNES: single linkage")
plot(spam.agnes.complete, which.plot=1, main="AGNES: complete linkage")
plot(spam.diana, which.plot=1, main="DIANA")
par(mfrow=c(1,1))
spam.agnes.avg.k2 <- cutree(spam.agnes.avg, k=2) #odcinanie klastróW
spam.diana.k2 <- cutree(spam.diana, k=2)
@

<<tot_internal_PCA, echo=FALSE, eval=FALSE, warning=FALSE, fig.cap="WskaŸniki wewnêtrzne: silhouette">>=
spam.cechy<-spam.PCA[,1:11]
mac_pod<-daisy(spam.cechy)
############### silhuette ###################
# kmeans
cl2.kmeans <- kmeans(spam.cechy, centers=2)
cl3.kmeans <- kmeans(spam.cechy, centers=3)
cl4.kmeans <- kmeans(spam.cechy, centers=4)
cl5.kmeans <- kmeans(spam.cechy, centers=5)
cl6.kmeans <- kmeans(spam.cechy, centers=6)

sil.k2.kmeans <- silhouette(cl2.kmeans$cluster, mac_pod)
sil.k3.kmeans <- silhouette(cl3.kmeans$cluster, mac_pod)
sil.k4.kmeans <- silhouette(cl4.kmeans$cluster, mac_pod)
sil.k5.kmeans <- silhouette(cl5.kmeans$cluster, mac_pod)
sil.k6.kmeans <- silhouette(cl6.kmeans$cluster, mac_pod)

# pam
cl2.pam <- pam(spam.cechy, k=2)
cl3.pam <- pam(spam.cechy, k=3)
cl4.pam <- pam(spam.cechy, k=4)
cl5.pam <- pam(spam.cechy, k=5)
cl6.pam <- pam(spam.cechy, k=6)

sil.k2.pam <- silhouette(cl2.pam, mac_pod)
sil.k3.pam <- silhouette(cl3.pam, mac_pod)
sil.k4.pam <- silhouette(cl4.pam, mac_pod)
sil.k5.pam <- silhouette(cl5.pam, mac_pod)
sil.k6.pam <- silhouette(cl6.pam, mac_pod)

#agnes
agnes_spam<-agnes(spam.cechy)
cl2.agnes <- cutree(agnes_spam, k=2)
cl3.agnes <- cutree(agnes_spam, k=3)
cl4.agnes <- cutree(agnes_spam, k=4)
cl5.agnes <- cutree(agnes_spam, k=5)
cl6.agnes <- cutree(agnes_spam, k=6)

sil.k2.agnes <- silhouette(cl2.agnes, mac_pod)
sil.k3.agnes <- silhouette(cl3.agnes, mac_pod)
sil.k4.agnes <- silhouette(cl4.agnes, mac_pod)
sil.k5.agnes <- silhouette(cl5.agnes, mac_pod)
sil.k6.agnes <- silhouette(cl6.agnes, mac_pod)

agnes_spamS<-agnes(spam.cechy, method="single")
cl2.agnesS <- cutree(agnes_spamS, k=2)
cl3.agnesS <- cutree(agnes_spamS, k=3)
cl4.agnesS <- cutree(agnes_spamS, k=4)
cl5.agnesS <- cutree(agnes_spamS, k=5)
cl6.agnesS <- cutree(agnes_spamS, k=6)

sil.k2.agnesS <- silhouette(cl2.agnesS, mac_pod)
sil.k3.agnesS <- silhouette(cl3.agnesS, mac_pod)
sil.k4.agnesS <- silhouette(cl4.agnesS, mac_pod)
sil.k5.agnesS <- silhouette(cl5.agnesS, mac_pod)
sil.k6.agnesS <- silhouette(cl6.agnesS, mac_pod)

agnes_spamC<-agnes(spam.cechy)
cl2.agnesC <- cutree(agnes_spamC, k=2)
cl3.agnesC <- cutree(agnes_spamC, k=3)
cl4.agnesC <- cutree(agnes_spamC, k=4)
cl5.agnesC <- cutree(agnes_spamC, k=5)
cl6.agnesC <- cutree(agnes_spamC, k=6)

sil.k2.agnesC <- silhouette(cl2.agnesC, mac_pod)
sil.k3.agnesC <- silhouette(cl3.agnesC, mac_pod)
sil.k4.agnesC <- silhouette(cl4.agnesC, mac_pod)
sil.k5.agnesC <- silhouette(cl5.agnesC, mac_pod)
sil.k6.agnesC <- silhouette(cl6.agnesC, mac_pod)


# diana
diana_spam<- diana(spam.cechy)
cl2.diana <- cutree(diana_spam, k=2)
cl3.diana <- cutree(diana_spam, k=3)
cl4.diana <- cutree(diana_spam, k=4)
cl5.diana <- cutree(diana_spam, k=5)
cl6.diana <- cutree(diana_spam, k=6)

sil.k2.diana <- silhouette(cl2.diana, mac_pod)
sil.k3.diana <- silhouette(cl3.diana, mac_pod)
sil.k4.diana <- silhouette(cl4.diana, mac_pod)
sil.k5.diana <- silhouette(cl5.diana, mac_pod)
sil.k6.diana <- silhouette(cl6.diana, mac_pod)

plot(c(2:6), c(
summary(sil.k2.kmeans)$si.summary[[4]],
summary(sil.k3.kmeans)$si.summary[[4]],
summary(sil.k4.kmeans)$si.summary[[4]],
summary(sil.k5.kmeans)$si.summary[[4]],
summary(sil.k6.kmeans)$si.summary[[4]]), xlab="Silhouette", ylab="Liczba klastrów", ylim=c(0.5, 1), type='b', pch=8, col="hotpink4", lwd=2, main="Silhouette")
lines( c(2:6),
c(summary(sil.k2.pam)$si.summary[[4]],
summary(sil.k3.pam)$si.summary[[4]],
summary(sil.k4.pam)$si.summary[[4]],
summary(sil.k5.pam)$si.summary[[4]],
summary(sil.k6.pam)$si.summary[[4]]), type='b', pch=9, col="pink", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnes)$si.summary[[4]],
summary(sil.k3.agnes)$si.summary[[4]],
summary(sil.k4.agnes)$si.summary[[4]],
summary(sil.k5.agnes)$si.summary[[4]],
summary(sil.k6.agnes)$si.summary[[4]]), type='b', pch=10, col="royalblue", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnesS)$si.summary[[4]],
summary(sil.k3.agnesS)$si.summary[[4]],
summary(sil.k4.agnesS)$si.summary[[4]],
summary(sil.k5.agnesS)$si.summary[[4]],
summary(sil.k6.agnesS)$si.summary[[4]]), type='b', pch=12, col="grey", lwd=2)
lines( c(2:6),
c(summary(sil.k2.agnesC)$si.summary[[4]],
summary(sil.k3.agnesC)$si.summary[[4]],
summary(sil.k4.agnesC)$si.summary[[4]],
summary(sil.k5.agnesC)$si.summary[[4]],
summary(sil.k6.agnesC)$si.summary[[4]]), type='b', pch=13, col="black", lwd=2)
lines( c(2:6),
c(summary(sil.k2.diana)$si.summary[[4]],
summary(sil.k3.diana)$si.summary[[4]],
summary(sil.k4.diana)$si.summary[[4]],
summary(sil.k5.diana)$si.summary[[4]],
summary(sil.k6.diana)$si.summary[[4]]), type='b', pch=11, col="orchid", lwd=2)
legend("bottomleft", c("kmeans", "pam", "agnes", "diana"), col=c("hotpink4", "pink", "royalblue","grey","black", "orchid"), pch=c(8,9,10,12, 13,11), cex=0.7, title="Legenda")
@

<<dunn_PCA, echo=FALSE, eval=FALSE, warning=FALSE, fig.cap="WskaŸniki wewnêtrzne: wsk. Dunn'a">>=
### WSKANIK DUNN'A ###
plot ( c(2:6), c(dunn(distance=as.matrix(mac_pod), cl2.kmeans$cluster),
dunn(as.matrix(mac_pod), cl3.kmeans$cluster),
dunn(as.matrix(mac_pod), cl4.kmeans$cluster),
dunn(as.matrix(mac_pod), cl5.kmeans$cluster),
dunn(as.matrix(mac_pod), cl6.kmeans$cluster)), main="WskaŸnik Dunn'a", ylim=c(0, 1), xlab="WskaŸnik Dunn'a", ylab="Liczba klastrów", type='b', lwd=2, pch=8, col="hotpink4")
lines( c(2:6),
c(dunn(distance=as.matrix(mac_pod), cl2.pam$clustering),
dunn(as.matrix(mac_pod), cl3.pam$clustering),
dunn(as.matrix(mac_pod), cl4.pam$clustering),
dunn(as.matrix(mac_pod), cl5.pam$clustering),
dunn(as.matrix(mac_pod), cl6.pam$clustering)), type='b', pch=9, lwd=2, col="pink")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnes),
dunn(as.matrix(mac_pod), cl3.agnes),
dunn(as.matrix(mac_pod), cl4.agnes),
dunn(as.matrix(mac_pod), cl5.agnes),
dunn(as.matrix(mac_pod), cl6.agnes)), type='b', lwd=2, pch=10, col="royalblue")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnesS),
dunn(as.matrix(mac_pod), cl3.agnesS),
dunn(as.matrix(mac_pod), cl4.agnesS),
dunn(as.matrix(mac_pod), cl5.agnesS),
dunn(as.matrix(mac_pod), cl6.agnesS)), type='b', lwd=2, pch=12, col="grey")
lines( c(2:6), 
c(dunn(distance=as.matrix(mac_pod), cl2.agnesC),
dunn(as.matrix(mac_pod), cl3.agnesC),
dunn(as.matrix(mac_pod), cl4.agnesC),
dunn(as.matrix(mac_pod), cl5.agnesC),
dunn(as.matrix(mac_pod), cl6.agnesC)), type='b', lwd=2, pch=13, col="black")
lines( c(2:6),
c(dunn(distance=as.matrix(mac_pod), cl2.diana),
dunn(as.matrix(mac_pod), cl3.diana),
dunn(as.matrix(mac_pod), cl4.diana),
dunn(as.matrix(mac_pod), cl5.diana),
dunn(as.matrix(mac_pod), cl6.diana)), type='b', lwd=2, pch=11, col="orchid")
legend("topright", c("kmeans", "pam", "agnes_a", "agnes_s", "agnes_c", "diana"), col=c("hotpink4", "pink", "royalblue", "grey", "black","orchid"), pch=c(8,9,10,12, 13,11), cex=0.7, title="Legenda")
@

<<zgodnosc_partycji2_PCA, echo=FALSE, eval=FALSE, results='asis'>>=

# porównanie wynikow grupowania z rzeczywist¹ przynaleznoscia do klas
tab.spam.kmeans <- table(kmeans.k2$cluster, spam$spam)
#matchClasses(tab.spam.kmeans, method="exact")

tab.spam.pam <- table(spam.pam2$clustering, spam$spam)
#matchClasses(tab.spam.pam, method="exact")

tab.spam.agnes <- table(cl2.agnes, spam$spam)
tab.spam.agnesS <- table(cl2.agnesS, spam$spam)
tab.spam.agnesC <- table(cl2.agnesC, spam$spam)
#matchClasses(tab.spam.agnes, method="exact")

tab.spam.diana <- table(spam.diana.k2, spam$spam)
#matchClasses(tab.spam.diana, method="exact")

tab.pam.agnes <- table(spam.pam2$clustering, spam.agnes.avg.k2)
#matchClasses(tab.pam.agnes, method="exact")

w2<-c(tab.spam.pam[1],tab.spam.pam[2],tab.spam.pam[3],tab.spam.pam[4], 100*( tab.spam.kmeans[1]+tab.spam.kmeans[4] )/4601)
w1<-c(tab.spam.kmeans[1],tab.spam.kmeans[2],tab.spam.kmeans[3],tab.spam.kmeans[4], 100*( tab.spam.pam[1]+tab.spam.pam[4] )/4601)
w3<-c(tab.spam.agnes[1],tab.spam.agnes[2],tab.spam.agnes[3],tab.spam.agnes[4], 100*( tab.spam.agnes[1]+tab.spam.agnes[4] )/4601)
w3S<-c(tab.spam.agnesS[1],tab.spam.agnesS[2],tab.spam.agnesS[3],tab.spam.agnesS[4], 100*( tab.spam.agnesS[1]+tab.spam.agnesS[4] )/4601)
w3C<-c(tab.spam.agnesC[1],tab.spam.agnesC[2],tab.spam.agnesC[3],tab.spam.agnesC[4], 100*( tab.spam.agnesC[1]+tab.spam.agnesC[4] )/4601)
w4<-c(tab.spam.diana[1],tab.spam.diana[2],tab.spam.diana[3],tab.spam.diana[4], 100*( tab.spam.diana[1]+tab.spam.diana[4] )/4601)

w<-c("k-means", "pam", "agnes_a", "agnes_s","agnes_c","diana")
k<-c("e-mail_1","e-mail_2", "spam_1","spam_2", "dopasow_proc")
macierz<-rbind(w1,w2,w3,w3S,w3C,w4)
dimnames(macierz)=list(w,k)
tabela<-xtable(macierz, digits=0, row.names=FALSE, caption="Dopasowanie klas", label="tabela:tabela")

# align(tabela)<-"|c|c|c|c|c|c|"
print(tabela, type="latex", table.placement="H", sanitize.text.function = function(x) {x})


@

<<wsk_zew_Rand_jaccard_fawkl_PCA, echo=FALSE, eval=FALSE, fig.cap="WskaŸniki zewnêtrzne: wsk. Randa">>=

pred2.kmeans <- as.integer(cl2.kmeans$cluster)
pred3.kmeans <- as.integer(cl3.kmeans$cluster)
pred4.kmeans <- as.integer(cl4.kmeans$cluster)
pred5.kmeans <- as.integer(cl5.kmeans$cluster)
pred6.kmeans <- as.integer(cl6.kmeans$cluster)

pred2.pam <- as.integer(cl2.pam$clustering)
pred3.pam <- as.integer(cl3.pam$clustering)
pred4.pam <- as.integer(cl4.pam$clustering)
pred5.pam <- as.integer(cl5.pam$clustering)
pred6.pam <- as.integer(cl6.pam$clustering)

pred2.agnes <- as.integer(cl2.agnes)
pred3.agnes <- as.integer(cl3.agnes)
pred4.agnes <- as.integer(cl4.agnes)
pred5.agnes <- as.integer(cl5.agnes)
pred6.agnes <- as.integer(cl6.agnes)

pred2.agnesS <- as.integer(cl2.agnesS)
pred3.agnesS <- as.integer(cl3.agnesS)
pred4.agnesS <- as.integer(cl4.agnesS)
pred5.agnesS <- as.integer(cl5.agnesS)
pred6.agnesS <- as.integer(cl6.agnesS)

pred2.agnesC <- as.integer(cl2.agnesC)
pred3.agnesC <- as.integer(cl3.agnesC)
pred4.agnesC <- as.integer(cl4.agnesC)
pred5.agnesC <- as.integer(cl5.agnesC)
pred6.agnesC <- as.integer(cl6.agnesC)

pred2.diana <- as.integer(cl2.diana)
pred3.diana <- as.integer(cl3.diana)
pred4.diana <- as.integer(cl4.diana)
pred5.diana <- as.integer(cl5.diana)
pred6.diana <- as.integer(cl6.diana)


std2kmeans <- std.ext(pred2.kmeans, as.integer(spam$spam))
rand2kmeans <- clv.Rand(std2kmeans)
jaccard2kmeans <- clv.Jaccard(std2kmeans)
folk.mal2kmeans <- clv.Folkes.Mallows(std2kmeans)

std3kmeans <- std.ext(pred3.kmeans, as.integer(spam$spam))
rand3kmeans <- clv.Rand(std3kmeans)
jaccard3kmeans <- clv.Jaccard(std3kmeans)
folk.mal3kmeans <- clv.Folkes.Mallows(std3kmeans)

std4kmeans <- std.ext(pred4.kmeans, as.integer(spam$spam))
rand4kmeans <- clv.Rand(std4kmeans)
jaccard4kmeans <- clv.Jaccard(std4kmeans)
folk.mal4kmeans <- clv.Folkes.Mallows(std4kmeans)

std5kmeans <- std.ext(pred5.kmeans, as.integer(spam$spam))
rand5kmeans <- clv.Rand(std5kmeans)
jaccard5kmeans <- clv.Jaccard(std5kmeans)
folk.mal5kmeans <- clv.Folkes.Mallows(std5kmeans)

std6kmeans <- std.ext(pred6.kmeans, as.integer(spam$spam))
rand6kmeans <- clv.Rand(std6kmeans)
jaccard6kmeans <- clv.Jaccard(std6kmeans)
folk.mal6kmeans <- clv.Folkes.Mallows(std6kmeans)

###

std2pam <- std.ext(pred2.pam, as.integer(spam$spam))
rand2pam <- clv.Rand(std2pam)
jaccard2pam <- clv.Jaccard(std2pam)
folk.mal2pam <- clv.Folkes.Mallows(std2pam)

std3pam <- std.ext(pred3.pam, as.integer(spam$spam))
rand3pam <- clv.Rand(std3pam)
jaccard3pam <- clv.Jaccard(std3pam)
folk.mal3pam <- clv.Folkes.Mallows(std3pam)

std4pam <- std.ext(pred4.pam, as.integer(spam$spam))
rand4pam <- clv.Rand(std4pam)
jaccard4pam <- clv.Jaccard(std4pam)
folk.mal4pam <- clv.Folkes.Mallows(std4pam)

std5pam <- std.ext(pred5.pam, as.integer(spam$spam))
rand5pam <- clv.Rand(std5pam)
jaccard5pam <- clv.Jaccard(std5pam)
folk.mal5pam <- clv.Folkes.Mallows(std5pam)

std6pam <- std.ext(pred6.pam, as.integer(spam$spam))
rand6pam <- clv.Rand(std6pam)
jaccard6pam <- clv.Jaccard(std6pam)
folk.mal6pam <- clv.Folkes.Mallows(std6pam)

## 

std2agnes <- std.ext(pred2.agnes, as.integer(spam$spam))
rand2agnes <- clv.Rand(std2agnes)
jaccard2agnes <- clv.Jaccard(std2agnes)
folk.mal2agnes <- clv.Folkes.Mallows(std2agnes)

std3agnes <- std.ext(pred3.agnes, as.integer(spam$spam))
rand3agnes <- clv.Rand(std3agnes)
jaccard3agnes <- clv.Jaccard(std3agnes)
folk.mal3agnes <- clv.Folkes.Mallows(std3agnes)

std4agnes <- std.ext(pred4.agnes, as.integer(spam$spam))
rand4agnes <- clv.Rand(std4agnes)
jaccard4agnes <- clv.Jaccard(std4agnes)
folk.mal4agnes <- clv.Folkes.Mallows(std4agnes)

std5agnes <- std.ext(pred5.agnes, as.integer(spam$spam))
rand5agnes <- clv.Rand(std5agnes)
jaccard5agnes <- clv.Jaccard(std5agnes)
folk.mal5agnes <- clv.Folkes.Mallows(std5agnes)

std6agnes <- std.ext(pred6.agnes, as.integer(spam$spam))
rand6agnes <- clv.Rand(std6agnes)
jaccard6agnes <- clv.Jaccard(std6agnes)
folk.mal6agnes <- clv.Folkes.Mallows(std6agnes)


std2agnesSS <- std.ext(pred2.agnesS, as.integer(spam$spam))
rand2agnesS <- clv.Rand(std2agnesS)
jaccard2agnesS <- clv.Jaccard(std2agnesS)
folk.mal2agnesS <- clv.Folkes.Mallows(std2agnesS)

std3agnesS <- std.ext(pred3.agnesS, as.integer(spam$spam))
rand3agnesS <- clv.Rand(std3agnesS)
jaccard3agnesS <- clv.Jaccard(std3agnesS)
folk.mal3agnesS <- clv.Folkes.Mallows(std3agnesS)

std4agnesS <- std.ext(pred4.agnesS, as.integer(spam$spam))
rand4agnesS <- clv.Rand(std4agnesS)
jaccard4agnesS <- clv.Jaccard(std4agnesS)
folk.mal4agnesS <- clv.Folkes.Mallows(std4agnesS)

std5agnesS <- std.ext(pred5.agnesS, as.integer(spam$spam))
rand5agnesS <- clv.Rand(std5agnesS)
jaccard5agnesS <- clv.Jaccard(std5agnesS)
folk.mal5agnesS <- clv.Folkes.Mallows(std5agnesS)

std6agnesS <- std.ext(pred6.agnesS, as.integer(spam$spam))
rand6agnesS <- clv.Rand(std6agnesS)
jaccard6agnesS <- clv.Jaccard(std6agnesS)
folk.mal6agnesS <- clv.Folkes.Mallows(std6agnesS)

##

std2agnesC <- std.ext(pred2.agnesC, as.integer(spam$spam))
rand2agnesC <- clv.Rand(std2agnesC)
jaccard2agnesC <- clv.Jaccard(std2agnesC)
folk.mal2agnesC <- clv.Folkes.Mallows(std2agnesC)

std3agnesC <- std.ext(pred3.agnesC, as.integer(spam$spam))
rand3agnesC <- clv.Rand(std3agnesC)
jaccard3agnesC <- clv.Jaccard(std3agnesC)
folk.mal3agnesC <- clv.Folkes.Mallows(std3agnesC)

std4agnesC <- std.ext(pred4.agnesC, as.integer(spam$spam))
rand4agnesC <- clv.Rand(std4agnesC)
jaccard4agnesC <- clv.Jaccard(std4agnesC)
folk.mal4agnesC <- clv.Folkes.Mallows(std4agnesC)

std5agnesC <- std.ext(pred5.agnesC, as.integer(spam$spam))
rand5agnesC <- clv.Rand(std5agnesC)
jaccard5agnesC <- clv.Jaccard(std5agnesC)
folk.mal5agnesC <- clv.Folkes.Mallows(std5agnesC)

std6agnesC <- std.ext(pred6.agnesC, as.integer(spam$spam))
rand6agnesC <- clv.Rand(std6agnesC)
jaccard6agnesC <- clv.Jaccard(std6agnesC)
folk.mal6agnesC <- clv.Folkes.Mallows(std6agnesC)

###

std2diana <- std.ext(pred2.diana, as.integer(spam$spam))
rand2diana <- clv.Rand(std2diana)
jaccard2diana <- clv.Jaccard(std2diana)
folk.mal2diana <- clv.Folkes.Mallows(std2diana)

std3diana <- std.ext(pred3.diana, as.integer(spam$spam))
rand3diana <- clv.Rand(std3diana)
jaccard3diana <- clv.Jaccard(std3diana)
folk.mal3diana <- clv.Folkes.Mallows(std3diana)

std4diana <- std.ext(pred4.diana, as.integer(spam$spam))
rand4diana <- clv.Rand(std4diana)
jaccard4diana <- clv.Jaccard(std4diana)
folk.mal4diana <- clv.Folkes.Mallows(std4diana)

std5diana <- std.ext(pred5.diana, as.integer(spam$spam))
rand5diana <- clv.Rand(std5diana)
jaccard5diana <- clv.Jaccard(std5diana)
folk.mal5diana <- clv.Folkes.Mallows(std5diana)

std6diana <- std.ext(pred6.diana, as.integer(spam$spam))
rand6diana <- clv.Rand(std6diana)
jaccard6diana <- clv.Jaccard(std6diana)
folk.mal6diana <- clv.Folkes.Mallows(std6diana)

plot(c(2:6), c(rand2kmeans, rand3kmeans, rand4kmeans, rand5kmeans, rand6kmeans), type='b', lwd=2, col="hotpink4", main="Rand", pch=8, ylim=c(0.5, 0.6), xlab="Liczba klastrów", ylab="Rand")
lines(c(2:6), c(rand2pam, rand3pam, rand4pam, rand5pam, rand6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(rand2agnes, rand3agnes, rand4agnes, rand5agnes, rand6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(rand2agnesS, rand3agnesS, rand4agnesS, rand5agnesS, rand6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(rand2agnesC, rand3agnesC, rand4agnesC, rand5agnesC, rand6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(rand2diana, rand3diana, rand4diana, rand5diana, rand6diana), type='b', lwd=2, col="orchid", pch=11)
legend("topleft", c("kmeans", "pam", "agnes", "diana"), col=c("hotpink4", "pink", "royalblue", "orchid"), pch=c(8,9,10,12, 13,11), cex=0.7, title="Legenda")

@

<<wsk_zew_cd_PCA, echo=FALSE, eval=FALSE, fig.width=8, fig.height=4.5, fig.cap="WskaŸniki zewnêtrzne: Jaccarda i Fowlkesa-Mallowsa">>=
par(mfrow=c(1,2))
plot(c(2:6), c(jaccard2kmeans, jaccard3kmeans, jaccard4kmeans, jaccard5kmeans, jaccard6kmeans), type='b', lwd=2, col="hotpink4", main="Jaccard", pch=8, ylim=c(0.3, 0.55), xlab="Liczba klastrów", ylab="Jaccard")
lines(c(2:6), c(jaccard2pam, jaccard3pam, jaccard4pam, jaccard5pam, jaccard6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(jaccard2agnes, jaccard3agnes, jaccard4agnes, jaccard5agnes, jaccard6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(jaccard2agnesS, jaccard3agnesS, jaccard4agnesS, jaccard5agnesS, jaccard6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(jaccard2agnesC, jaccard3agnesC, jaccard4agnesC, jaccard5agnesC, jaccard6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(jaccard2diana, jaccard3diana, jaccard4diana, jaccard5diana, jaccard6diana), type='b', lwd=2, col="orchid", pch=11)
legend("bottomleft", c("kmeans", "pam", "agnes", "diana"), col=c("hotpink4", "pink", "royalblue", "orchid"), pch=c(8,9,10,12,13,11), cex=0.7, title="Legenda")

plot(c(2:6), c(folk.mal2kmeans, folk.mal3kmeans, folk.mal4kmeans, folk.mal5kmeans, folk.mal6kmeans), type='b', lwd=2, col="hotpink4", main="folk.mal", pch=8, ylim=c(0.45, 0.75), xlab="Liczba klastrów", ylab="Fowlkes-Mallows")
lines(c(2:6), c(folk.mal2pam, folk.mal3pam, folk.mal4pam, folk.mal5pam, folk.mal6pam), type='b', lwd=2, col="pink", pch=9)
lines(c(2:6), c(folk.mal2agnes, folk.mal3agnes, folk.mal4agnes, folk.mal5agnes, folk.mal6agnes), type='b', lwd=2, col="royalblue", pch=10)
lines(c(2:6), c(folk.mal2agnesS, folk.mal3agnesS, folk.mal4agnesS, folk.mal5agnesS, folk.mal6agnesS), type='b', lwd=2, col="grey", pch=12)
lines(c(2:6), c(folk.mal2agnesC, folk.mal3agnesC, folk.mal4agnesC, folk.mal5agnesC, folk.mal6agnesC), type='b', lwd=2, col="black", pch=13)
lines(c(2:6), c(folk.mal2diana, folk.mal3diana, folk.mal4diana, folk.mal5diana, folk.mal6diana), type='b', lwd=2, col="orchid", pch=11)
legend("bottomleft", c("kmeans", "pam", "agnes", "diana"), col=c("hotpink4", "pink", "royalblue", "orchid"), pch=c(8,9,10,12,13,11), cex=0.7, title="Legenda")
par(mfrow=c(1,1))

@

\section{Podsumowanie}
Podsumowuj¹c, spoœród przeanalizowaniu licznych metod klasyfikacji, najlepsz¹ okaza³a siê byæ
XGBoost. Jednak wyniki uzyskane za pomoc¹ pozosta³ych rozwa¿anych
metod (poza Klasyfikatorem Naiwnym Bayesa), nie s¹ istotnie gorsze. W szczególnoœci bardzo 
dobr¹ skutecznoœæ uzyska³y metody Regresji Logistycznej i LDA, charakteryzuj¹ce siê znacznie mniejsz¹ 
z³o¿onoœci¹ obliczeniow¹ i interpretowalnoœci¹.
Jeœli chodzi o analizê skupieñ, rozwa¿one metody nie nios¹ za sob¹ jednoznacznej informacji o strukturze
wewnêtrznej danych. Ró¿norodnoœæ wyników wywo³uje w¹tpliwoœci. Podzia³ wynikaj¹cy z zastosowania powy¿szych metod
mo¿e nie byæ to¿samy z podzia³em na grupy "mail" i "spam" i mo¿e on reprezentowaæ inne niezane partycje, za którymi stoj¹ 
informacje dotycz¹ce pewnej grupy maili, których odtworzenie mo¿e byæ niemo¿liwe ze wzglêdu na strukturê danych 
(nie mamy pe³nych maili, tylko czêstotliwoœæ s³ów).


\end{document}