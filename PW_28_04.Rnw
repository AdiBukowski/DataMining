\documentclass[12pt, a4paper]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  % dodatkowe pakiety LaTeX'a
\usepackage[OT4]{polski}
\usepackage[cp1250]{inputenc}
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage{animate}
\newtheorem{theorem}{Twierdzenie}
\usepackage{mathtools}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ustawienia globalne
<<ustawienia_globalne, echo=FALSE, warning=FALSE,results='hide',message=FALSE>>=
library(knitr)
library(xtable) #pakiet do tworzenia tabel w formacie LaTeX'a
library(animation)
library(ElemStatLearn)
library(MASS)
library(cluster)
library(ggplot2)
library(ROCR)
library(stats)
library(e1071)
library(neuralnet)
library(randomForest)
library(mlr)
library(kknn)
library(corrgram)
library(clValid)
library(mclust)

opts_chunk$set(fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=4,message=FALSE)
# UWAGA: w razie potrzeby mo¿na zmieniaæ te ustawienia w danym chunk'u!
@
  
  
  
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% strona tytulowa
\title{Filtrowanie spamu}
\author{Adrian Bukowski  Anna Miko³ajczyk}
\maketitle
\tableofcontents 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% MULTIPLOT %%% dzia³a jak par(mfrow=c(x,y)) dla ggplotów %%%
%%% wywo³anie: multiplot(wykres1, wykres2,. .. , wykresn, cols=liczba kolumn) %%%
<<multiplot, echo=FALSE, eval=TRUE>>=
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Wstêp oraz analiza opisowa}
Przedmiotem naszych rozwa¿añ s¹ dane dotycz¹ce zawartoœci 4601 wiadomoœci e-mail. Celem analiz jest filtrowanie spamu, tzn. rozró¿nienie spamu od po¿adanych wiadomoœci. Mamy do czynienia z 57 zmiennymi, spoœród których:
\begin{itemize}
\item 48 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego s³owa w mailu (za s³owo uznajemy dowolny ci¹g liter i cyfr)
\item 6 przyjmuje wartoœci od 0 do 100 i oznacza procentowy udzia³ danego znaku w mailu 
\item 1 przyjmuje wartoœci dodatnie i oznacza œredni¹ d³ugoœæ nieprzerywanych ci¹gów wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza d³ugoœæ najd³u¿szego nieprzerwanego ci¹gu wielkich liter
\item 1 przyjmuje wartoœci naturalne i oznacza ³¹czna iloœæ wielkich liter w mailu
\end{itemize}
Oprócz tego dane zawieraj¹ kolumnê spam/mail oznaczaj¹c¹ czy dany mail jest spamem. Mamy wiêc do czynienia z zadaniem klasyfikacji. Przyjrzyjmy siê danym.
<<>>=
data("spam")
dim(spam)
X<-spam[,1:(dim(spam)[2]-1)]
y<-spam[,dim(spam)[2]]
@
Przed wykonaniem analiz sprawdziliœmy czy dane s¹ dobrze wczytane, zmienne okaza³y siê zgodne z opisem. Upewniliœmy siê równie¿, ¿e nie wystêpuj¹ brakuj¹ce dane.
<<czy_dobrze_wczytane, echo=FALSE, eval=FALSE>>=
sapply(X,class)
@

<<brakujace_dane, echo=FALSE, eval=FALSE>>=
sum(is.na(X))
@
Na pocz¹tku analiz przyjrzeliœmy siê poszczególnym zmiennym, wyznaczaj¹c podstawowe statystyki opisowe (w zwi¹zku z du¿¹ iloœci¹ zmiennych nie umieszczamy ich w raporcie) i kowariancje pomiêdzy nimi (prezentujemy wynik w postaci tzw. heatmap, czyli mapy ciep³a).
<<pods_statystyki, echo=FALSE, eval=FALSE>>=
summary(X)
@

<<kowariancja_zmiennych, echo=FALSE, eval=TRUE, fig.height=7, fig.width=7, fig.cap="Kowariancja miêdzy zmiennymi">>=
kowariancja <- cov(X)
heatmap(kowariancja)
@

Nastêpnie skupiliœmy sie na zmiennej objaœnianej
<<zm_objasniajaca, echo=TRUE, eval=TRUE>>=
class(y)
levels(y)
@
Jest to zmienna typu "factor" o dwóch poziomach - "email" i "spam".

W kolejnym kroku, zbadaliœmy jak dziel¹ siê dane, którymi dysponujemy, ze wzglêdu na zmienn¹ objaœnian¹. Rozk³ad mo¿emy obserwowaæ na poni¿szym wykresie s³upkowym.
<<podzial_wzgl_y, echo=FALSE, eval=TRUE, fig.cap="Rozk³ad wiadomoœci na spam i po¿¹dane e-maile">>=
tab<-table(y)
tab
as.matrix(tab)
data<-as.data.frame(tab)
colnames(data)<-c('type','freq')
ggplot(data, aes(x=as.factor(type), y=freq,fill=as.factor(type)))+geom_bar(stat = "identity")+ labs(x="", y='Ilosc') + theme(legend.position="none")
prop.table(tab)
@
Okaza³o siê, ¿e oko³o 60\% obserwacji stanowi¹ po¿¹dane e-maile, a 40\% spam. 

Posi³kuj¹c siê dokumentacj¹ danych, aby nasze analizy by³y bardziej œwiadome, dodaliœmy nazwy kolumn. 
<<nazwy_kolumn, echo=FALSE, eval=TRUE>>=
spamColNames <- c("word_freq_make", "word_freq_address", "word_freq_all", "word_freq_3d", 
    "word_freq_our", "word_freq_over", "word_freq_remove", "word_freq_internet", 
    "word_freq_order", "word_freq_mail", "word_freq_receive", "word_freq_will", 
    "word_freq_people", "word_freq_report", "word_freq_addresses", "word_freq_free", 
    "word_freq_business", "word_freq_email", "word_freq_you", "word_freq_credit", 
    "word_freq_your", "word_freq_font", "word_freq_000", "word_freq_money", 
    "word_freq_hp", "word_freq_hpl", "word_freq_george", "word_freq_650", "word_freq_lab", 
    "word_freq_labs", "word_freq_telnet", "word_freq_857", "word_freq_data", 
    "word_freq_415", "word_freq_85", "word_freq_technology", "word_freq_1999", 
    "word_freq_parts", "word_freq_pm", "word_freq_direct", "word_freq_cs", "word_freq_meeting", 
    "word_freq_original", "word_freq_project", "word_freq_re", "word_freq_edu", 
    "word_freq_table", "word_freq_conference", "char_freq_ch;", "char_freq_ch(", 
    "char_freq_ch[", "char_freq_ch!", "char_freq_ch$", "char_freq_ch#", "capital_run_length_average", 
    "capital_run_length_longest", "capital_run_length_total")
colnames(X)<-spamColNames
@
W celu wy³apania ró¿nic pomiêdzy obserwacjami które s¹ spamem, a tymi które nie s¹, podzieliliœmy ca³¹ próbkê na dwie roz³¹czne. Chcieliœmy równie¿ sprawdziæ czym wyró¿niaj¹ siê wiadomoœci bêd¹ce spamem, a czym pozosta³e.
Poni¿sze wykresy przedstawiaj¹, które s³owa pojawiaj¹ siê z najwiêksz¹ œredni¹ czêstotliwoœci¹ we wspomnianych grupach.
<<slowa_podzial, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=8, fig.cap="Najwiêksze œrednie czêstotliwoœci pojawiania siê s³ów wœród spamu i wiadomoœci po¿¹danych">>=
X.spam<-X[y=='spam',1:48]
X.email<-X[y=='email',1:48]
avg.X.spam <- sort(sapply(X.spam,mean),decreasing = TRUE)
avg.X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
avg.X.spam<-as.data.frame(avg.X.spam[1:10])
colnames(avg.X.spam)<-'avg_word_freq'
avg.X.email<-as.data.frame(avg.X.email[1:10])
colnames(avg.X.email)<-'avg_word_freq'
w1_spam <- ggplot(avg.X.spam, aes(x=reorder(rownames(avg.X.spam),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) +ggtitle("Spam")
w2_email <- ggplot(avg.X.email, aes(x=reorder(rownames(avg.X.email),-avg_word_freq),y=avg_word_freq))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) +ggtitle("E-mail")
multiplot(w1_spam, w2_email, cols=2)
@
£atwo zauwa¿yæ, ¿e najczêœciej mamy do czynienia ze s³owem "you", jednak wystepuje ono w obu grupach, zatem prawdopodobnie, nie ró¿nicuje ich we w³aœciwy sposób. Drugie w kolejnoœci, jeœli chodzi o œredni procentowy udzia³ s³owa we wiadomoœci, w przypadku spamu, jest s³owo "your", a w przypadku e-maili s³owa "George" i "hp".
Z kolejnych wykresów, mo¿emy odczytaæ jakie znaki stanowi¹ œrednio najwiêkszy procentowy udzia³ w wiadomoœci, w przypadkach spamu i zwyk³ych e-maili.
<<znaki_podzial, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=6, fig.cap="Najwiêksze œrednie czêstotliwoœci pojawiania siê znaków w spamie i po¿¹danych wiadomoœciach">>=
X.spam<-X[y=='spam', 49:54]
X.email<-X[y=='email', 49:54]
X.spam <- sort(sapply(X.spam, mean),decreasing = TRUE)
X.email <- sort(sapply(X.email, mean),decreasing = TRUE)
X.spam <- cbind(X.spam,'spam')
X.email <- cbind(X.email,'email')
colnames(X.spam) <- c('avg.char.freq','type')
colnames(X.email) <- c('avg.char.freq','type')
X.char.freq <- rbind(X.spam,X.email)
X.char.freq <- cbind(rownames(X.char.freq),X.char.freq)
colnames(X.char.freq) <- c('char', 'avg.char.freq', 'type')
X.char.freq <- as.data.frame(X.char.freq) 
ggplot(X.char.freq, aes(x=as.factor(char), y = avg.char.freq, fill=type))+geom_bar(stat = "identity",position = "dodge")+ theme(axis.text.x = element_text(angle = 45, hjust = 1))
@
Widzimy, ¿e œrednio w spamie, wiêkszy procentowy udzia³ maj¹ znaki !, \#, \$, a w e-mailach ), ], ;. Mo¿na przypuszczaæ, ¿e wystêpowanie znaków \$ i ] jest istotne w rozpoznawaniu spamu, poniewa¿ w ich przypadku obserwujemy najwiêksz¹ ró¿nicê pomiêdzy œrednim procentowym udzia³em w spamie i w e-mailu.
Koñcz¹c wstêpne analizy, zajêliœmy siê jeszcze 3 ostatnimi zmiennymi, czyli œredni¹ d³ugoœci¹ nieprzerwanych ci¹gów wielkich liter, d³ugoœci¹ najd³u¿szego nieprzerywanego ci¹gu wielkich liter oraz ³¹czn¹ iloœci¹ wielkich liter w mailu.
<<wielkie_litery_podzial, echo=FALSE, eval=TRUE, fig.height=3, fig.width=8, fig.cap="Analiza wielkich liter w spamie i w po¿¹danych wiadomoœciach", warning=FALSE>>=
par(mfrow=c(1,3))
col.55<-as.data.frame(as.matrix(by(X[,55],y,mean)))
col.56<-as.data.frame(as.matrix(by(X[,56],y,mean)))
col.57<-as.data.frame(as.matrix(by(X[,57],y,mean)))
w1<-ggplot(col.55, aes(x=rownames(col.55),y=V1,fill=rownames(col.55)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Sr. dl. ciagu wlk. liter")
w2<-ggplot(col.56, aes(x=rownames(col.56),y=V1,fill=rownames(col.56)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Najdluzszy ciag wlk. liter")
w3<-ggplot(col.57, aes(x=rownames(col.57),y=V1,fill=rownames(col.57)))+geom_bar(stat='identity') + theme(legend.position="none") + ggtitle("Laczna ilosc")
multiplot(w1,w2,w3, cols=3)
@
Powy¿sze wykresy sugeruj¹, ¿e wielkie litery znacznie wiêksz¹ rolê odgrywaj¹ w spamie. Przyjrzyjmy siê histogramom czêstoœci wystêpowania niektórych s³ów:
<<>>=
q1<-qplot(X$word_freq_you, geom="histogram") +xlab("Procentowy udzia³ s³owa 'you' w mailu")
q2<-qplot(X$word_freq_will, geom="histogram")+xlab("Procentowy udzia³ s³owa 'will' w mailu")
multiplot( q1,q2, cols=2)
@
Jak widaæ charakterystyczne dla naszych danych jest czêste wystêpowanie wartoœci 0. Dodatkowo dane nie przypominaj¹ rozk³adu normalnego i s¹ ciê¿koogonowe. Warto zatem rozwa¿yæ transformacjê logarytmiczn¹. Ze wzglêdu na wspomniane wartoœci zerowe rozwa¿ymy jednak transformacjê $\log (x+0.1)$.
<<>>=
q1<-qplot(log(X$word_freq_you+0.1), geom="histogram") +xlab("Logarytm z procentowego udzia³u s³owa 'you' w mailu")
q2<-qplot(log(X$word_freq_will+0.1), geom="histogram")+xlab("Logarytm z procentowego udzia³u s³owa 'will' w mailu")
multiplot( q1,q2, cols=2)
@
Oczywiœcie dalej mamy do czynienia z atomem w punkcie $\log (0.1)$, jednak pozosta³e dane du¿o bardziej przypominaj¹ rozk³ad normalny. Transformacjê zastosujemy do metod LDA i LR (w pozosta³ych metodach pogorsza³a ona wyniki).
Po wstêpnej analizie przechodzimy do bardziej z³o¿onych rozwa¿añ zwi¹zanych z postawionym problemem.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Klasyfikacja}
Zajmiemy siê teraz zagadnieniem klasyfikacji. Wykorzystamy pakiet mlr, który umo¿liwia zastosowanie ró¿nych metod w szybki sposób. Zaczynamy od stworzenia zadania klasyfikacji. Dostrajanie parametróW i badanie skutecznoœci zostanie wykonane za pomoc¹ walidacji krzy¿owej na 80\% danych, a nastêpnie na pozosta³ych 20\% sprawdzimy uzyskan¹ skutecznoœæ.
<<zad_klasyf, echo=TRUE, eval=TRUE>>=
spam.log<-spam
spam.log[,-dim(spam)[2]]<-log(spam[,-dim(spam)[2]]+0.1)
smp<- sample(dim(spam)[1],dim(spam)[1]*0.2)
test.log<- spam.log[smp,]
train.log<-spam.log[-smp,]
test <-spam[smp,]
train<-spam[-smp,]
task.log <- makeClassifTask(data = train.log, target = "spam")
task<-makeClassifTask(data=train, target = "spam")
data("spam")
@
W kolejnym roku napisaliœmy funkcjê do rysowania krzywej ROC.
<<roc, echo=TRUE, eval=TRUE>>=
ROC<-function(pred.prob,true.labels){
  pred.ROCR <- ROCR::prediction(pred.prob, true.labels)
  perf.ROCR <- ROCR::performance(pred.ROCR, "tpr", "fpr")
  plot(perf.ROCR, print.cutoffs.at=seq(0.1,1,0.1), colorize=TRUE, lwd=2)
}
@
W kolejnych podrozdzia³ach wyznaczymy klasyfikatory za pomoc¹ regresji logistycznej (RL), LDA, klasyfikatora Naiwnego Bayes'a, metody kNN, lasów losowych, SVM oraz XGBoost. Dla wszystkich klasyfikatorów zastosowana zostanie walidacja krzy¿owa z 5 podzbiorami. W celu porównania dopasowania porównamy dok³adnoœæ i AUC.

\subsection{Regresja Logistyczna}
Zaczynamy od  jednej z najpopularniejszych metod klasyfikacji, czyli regresji logistycznej. Wykorzystamy dane po przekszta³ceniu.
<<RL, echo=TRUE, eval=TRUE, warning=FALSE>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task.log, iters = 5,
                        stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.logistic$aggr
@
Jak widaæ ju¿ zwyk³a regresja logistyczna dobrze odró¿nia nasze dane - dok³adnoœæ wynosi prawie 94\%. Poni¿ej przedstawiamy krzyw¹ ROC.
<<RL_ROC, echo=FALSE, eval=TRUE, fig.cap="Regresja logistyczna: krzywa ROC">>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

\subsection{LDA}
Kolejnym klasyfikator otrzymamy za pomoc¹ metody LDA. Podobnie jak w regresjii logistycznej wykorzystamy dane po przekszta³ceniu.
<<LDA, echo=TRUE, eval=TRUE>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task.log, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.lda$aggr
@
Otrzymujemy niewiele gorszy wynik ni¿ przy u¿yciu regresji logistycznej.
<<LDA_ROC, echo=FALSE, eval=TRUE, fig.cap="LDA: krzywa ROC">>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

\subsection{Klasyfikator Naiwny Baysa}
Nastêpnym klasyfikatorem bêdzie klasyfikator naiwny Bayesa.
<<kNB, echo=TRUE, eval=TRUE>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task, iters = 5,
                     stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.bayes$aggr
@
Klasyfikator Bayesa poradzi³ sobie z tym zadaniem najgorzej z dotychczasowych klasyfikatorów. Wykres ROC dla tego klasyfikatora prezentuje siê nastêpuj¹co:

<<kNB_ROC, echo=FALSE, eval=TRUE, fig.cap="Naiwny klasyfikator Bayes'a: krzywa ROC">>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
Metoda k-Najbli¿szych S¹siadów jest nastêpn¹ z rozwa¿anych metod. W celu doboru liczby s¹siadów wykorzystamy metodê 'Grid search' na siatce od 1 do 10 s¹siadów.
<<kNN, echo=TRUE, eval=TRUE>>=
knn_params <- makeParamSet(
  makeDiscreteParam("k", values = c(1,2,3,4,5,6,7,8,9,10))
)
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.kknn", task = task, resampling = rdesc,
  par.set = knn_params, control = ctrl)
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob', par.vals = tuned_params$x)
cv.knn <- crossval(learner = knn.learner, task = task, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.knn$aggr
@
Algorytm wybra³ model z \Sexpr{tuned_params$x$k} s¹siadami. Uzyskuje ona dok³adnoœæ na poziomie nieca³ych 92\%, zatem wynik niewiele gorszy od regresji logistycznej. Poniewa¿ wykorzystaliœmy te same dane do strojenia parametru oraz ewaluacji modelu, powinniœmy zatem sprawdziæ jeszcze jak model radzi sobie na nowych danych (najlepiej wykorzystuj¹c walidacjê krzy¿ow¹), poniewa¿ jednak 'podwójna' walidacja krzy¿owa jest bardzo kosztowna obliczeniowo (zw³aszcza dla metod typu lasy losowe/xgboost/sieci neuronowe), zatem dla metody kNN jak i nastêpnych sprawdzimy skutecznoœæ na jednym zbiorze testowym.  
Wynik na zbiorze testowym:
<<echo=FALSE>>=
mod <- train(knn.learner, task= task)
test.pred<-predict(mod,newdata = test)
knn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
knn.test.acc
@
Jest on podobny do wyniku uzyskanego metod¹ walidacji krzy¿owej na zbiorze treningowym, co czyni model wiarygodnym.
Poni¿ej widzimy wykres ROC.
<<kNN_ROC, echo=FALSE, eval=TRUE, fig.cap="k-NN: krzywa ROC">>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@


\subsection{Lasy losowe}
Przyjrzyjmy siê równie¿  klasyfikacji za pomoc¹ lasów losowych. W celu doboru parametrów: liczby drzew, liczby zmiennych branych pod uwagê przy ka¿dym podziale, maksymalnej liczby liœci i minimalnej liczby zmiennych w liœciu, wykorzystamy metodê 'Random search' z odpowiednimi przedzia³ami pocz¹tkowymi. 
<<LL, echo=TRUE, eval=TRUE>>=
randForest_params <- makeParamSet(
  makeIntegerParam("ntree", lower = 100, upper = 500),
  makeIntegerParam("mtry", lower = 1, upper = 10),
  makeIntegerParam("maxnodes", lower = 5, upper = 50),
  makeIntegerParam("nodesize", lower = 1, upper = 15)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.randomForest", task = task, resampling = rdesc,
  par.set = randForest_params, control = ctrl)

randForest.learner <- makeLearner("classif.randomForest", predict.type = 'prob', par.vals = tuned_params$x)
cv.randForest <- crossval(learner = randForest.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.randForest$aggr
@
Po wybraniu odpowiednich parametrów model uzyska³ skutecznoœæ ponad 93\%. Zobaczmy jak wygl¹da wynik na zbiorze testowym:
<<>>=
mod <- train(randForest.learner, task= task)
test.pred<-predict(mod,newdata = test)
randForest.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
randForest.test.acc
@
Wynik na zbiorze testowym wynosi \Sexpr{randForest.test.acc}, zatem jest on podobny jak w zbiorze treningowym. Poni¿ej przedstawiono wykres krzywej ROC.
<<LL_ROC, echo=FALSE, eval=TRUE, fig.cap="Lasy losowe: krzywa ROC">>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

\subsection{Maszyna wektorów noœnych}
Kolejnym z rozwa¿anych klasyfikatorów jest SVM z j¹drem gaussowskim. W celu odpowiedniego dobrania parametrów $C$ i $\gamma$ zastosujemy metodê 'Random search', czyli losowe przeszukiwanie w którym podajemy odpowiedni zakres do przeszukania. 
<<SVM, echo=TRUE, eval=TRUE>>=
svm_params <- makeParamSet(
  makeNumericParam("C", lower = -1, upper = 10, trafo = function(x) 2^x),
  makeNumericParam("epsilon", lower = -1, upper = 10, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.ksvm", task = task, resampling = rdesc,
  par.set = svm_params, control = ctrl)
svm.learner <- setHyperPars(makeLearner("classif.ksvm", predict.type = 'prob'), par.vals = tuned_params$x)
cv.svm <- crossval(learner = svm.learner, task = task, iters = 5,
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.svm$aggr
@
Otrzymaliœmy wynik ponad 93\%. Dla parametrów $C$ i $\gamma$ odpowiednio \Sexpr{tuned_params$x$C} i \Sexpr{tuned_params$x$epsilon}. Zobaczmy jaki wynik otrzymamy na zbiorze testowym:
<<>>=
mod <- train(svm.learner, task= task)
test.pred<-predict(mod,newdata = test)
svm.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
svm.test.acc
@
Wykres krzywej ROC przedstawiono poni¿ej.
<<SVM_ROC, echo=FALSE, eval=TRUE, fig.cap="SVM: krzywa ROC">>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

\subsection{XGBoost}
Jednym z najskuteczniejszych algorytmów, wygrywaj¹cych w konkursach pozyskiwania wiedzy na stronach typu Kaggle jest znany algorytm XGBoost (eXtreme Gradient Boosting). Jest to przyk³ad algorytmu wykorzystuj¹cego boosting. Algorytm ze wzglêdu na z³o¿onoœæ posiada wiele hiperparametrów, które wybierzemy metod¹ 'Random search' podaj¹c tylko granice poszukiwañ.

<<>>=
xgb_params <- makeParamSet(
  makeIntegerParam("nrounds", lower = 100, upper = 500),
  makeIntegerParam("max_depth", lower = 1, upper = 10),
  makeNumericParam("eta", lower = .1, upper = .5),
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 3)
tuned_params <- tuneParams('classif.xgboost', task = task,resampling = resample_desc,par.set = xgb_params,
control = control)
xgboost.learner <- makeLearner("classif.xgboost", predict.type = 'prob', par.vals = tuned_params$x)
cv.xgboost <- crossval(learner = xgboost.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.xgboost$aggr
@
Jeden z obecnie najskuteczniejszych algorytmów, podobnie na tym zbiorze uzyska³ bardzo dobry wynik ponad 95\%. Zobaczmy jaki wynik uzyska³ na zbiorze testowym.
<<>>=
mod <- train(xgboost.learner, task= task)
test.pred<-predict(mod,newdata = test)
xgboost.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
xgboost.test.acc
@
Wykres krzywej ROC zaprezentowano poni¿ej.
<<XGBoost_ROC, echo=FALSE, eval=TRUE, fig.cap="XGBoost: krzywa ROC">>=
ROC(cv.xgboost$pred$data[,4],cv.xgboost$pred$data[,2])
@


\subsection{Porównanie}
<<porownanie_klasyf, echo=FALSE, eval=TRUE, results='asis', fig.cap="Skutecznoœæ metod klasyfikacji">>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr,cv.xgboost$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych','XGBoost')
colnames(wyniki)<-c('Skutecznoœæ','AUC', 'Czu³oœæ','Specyficznoœæ')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla danych "spam"')
print(xtab)
@
Najskuteczniejsz¹ metod¹ okaza³ siê XGBoost, jednak znacznie prostsze metody takie jak regresja logistyczna, która ponadto umo¿liwia interpretacjê modelu, daj¹ niemal¿e identyczne wyniki. Najmniej skuteczn¹ metod¹ jest klasyfikator naiwny Bayesa. 
<<roc_klasyf_razem, echo=FALSE, eval=TRUE>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
pred.xgboost<-getRRPredictions(cv.xgboost)
@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów.
<<por_ROC_klasyf, echo=FALSE, eval=TRUE, fig.width=8, fig.height=4.5, fig.cap="Porównanie krzywych ROC dla ró¿nych klasyfikatorów">>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm, xgboost = pred.xgboost), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@

\section{Redukcja wymiaru}
Poniewa¿ dysponujemy danymi z 58 zmiennymi, konieczna wydaje siê byæ redukcja wymiaru.

\subsection{PCA}
W tym celu wykorzystamy metodê PCA. Poni¿ej prezentujemy wykres osypiskowy i wykres skumulowanej wariancji, dziêki którym mo¿emy zaobserwowaæ jaki udzia³ w wyjaœnianiu zmiennoœci, maj¹ kolejne sk³adowe g³ówne. 
<<pca, echo=FALSE, eval=TRUE, fig.cap="Analiza zmiennoœci wyjaœnianej przez kolejne sk³adowe g³ówne", fig.width=8, fig.height=9>>=
#redukcja wymiaru
#pca
n<-dim(spam)[1]
spam.pca<-spam[,1:57]
spam.po.pca <- prcomp(spam.pca, retx=T, center=T, scale.=T) 
#print("Skladowe glowne:")
#print(spam.po.pca$rotation[,10])
#summary(spam.po.pca)

#analiza zmiennoœci wyjaœnianej przez sk³adowe g³ówne
wariancja <- ( spam.po.pca$sdev ^2)/sum(spam.po.pca$sdev^2) 
avg_var<-mean(wariancja)
#for(i in 1:57){
 # if(wariancja[i] < avg_var)
 # {print(i) 
 #}
#}
wariancja.narast <- cumsum(wariancja)
par(mfrow=c(2,1))
barplot(wariancja, ylim=c(0, 0.12))
abline(a=avg_var, b=0, col="red", lwd=2, lty=2)
text(x=50, y=avg_var+0.002, label = "œrednia wariancja", col="red")
barplot(wariancja.narast)
abline(a=0.25, b=0, col="red", lwd=2, lty=2)
text(x=2, y=0.27, label = "25%", col="red")
abline(a=0.5, b=0, col="orange", lwd=2, lty=2)
text(x=2, y=0.52, label = "50%", col="orange")
abline(a=0.75, b=0, col="green", lwd=2, lty=2)
text(x=2, y=0.77, label = "75%", col="green")
par(mfrow=c(2,1))
@
Przy tak du¿ej iloœci zmiennych, stawianie sobie progu np. 90\% wyjaœnianej zmiennoœci, zaprowadzi³o by nas do dalszego rozwa¿anie niemal¿e wszystkich zmiennych. Jednak nie taki by³ nasz cel, musimy zatem w inny sposób ustaliæ, ile sk³adowych g³ównych braæ pod uwagê. W tym celu wyznaczyliœmy wartoœæ œredni¹ wariancji i zaobserwowaliœmy, ¿e ka¿da z 20 pierwszych sk³adowych g³ównych, wyjaœnia wiêcej ni¿ œrednia wartoœæ zmiennoœci. Jednak weryfikuj¹c ten wynik, wykorzystuj¹c ocenê wizualn¹, ³atwo zauwa¿yæ, ¿e w przypadku sk³adowych 12-20 jest to niewielka ró¿nica, zatem rozs¹dnym wyborem wydaje siê byæ 11 sk³adowych g³ównych.

Pierwsze dwie sk³adowe g³ówne wyjaœniaj¹ zaledwie nieco ponad 17\% zmiennoœci. Poni¿ej prezentujemy wykres rozrzutu, w przestrzeni tych dwóch sk³adowych. 
<<pca_PCA1_PCA2, echo=FALSE, eval=TRUE, fig.cap="Wykres rozrzutu w przestrzeni dwóch pierwszych sk³adowych g³ównych">>=
#wizual.
plot(spam.po.pca$x[,1], spam.po.pca$x[,2], col=as.factor(y))
@



\section{Klasyfikacja z redukcj¹ wymiaru}
Spróbujmy teraz przeprowadziæ podobn¹ analizê z uprzednim zastosowaniem algorytmu PCA w celu redukcji wymiaru. Do dalszych analiz wybieramy 11 sk³adowych g³ównych. Porównamy wyniki wskaŸników takich jak w poprzednim roŸdziale, to zanczy skutecznoœci, AUC, czu³oœci i specyficznoœci. Po dobraniu parametrów do niektórych metod, sprawdzona zostanie skutecznoœæ na zbiorze testowym w celu porównania do zbioru treningowego. Dla ka¿dej metody zostan¹ przedstawione graficznie granice podzia³u dla pierwszych dwóch sk³adowych g³ównych.

<<red_pca, echo=FALSE, eval=TRUE>>=
X.pca <- prcomp(spam[,-dim(spam)[2]], retx = T)
@

<<red_pca2, echo=FALSE, eval=TRUE, warning=FALSE>>=
data('spam')
n<-11
X<-X.pca$x[,1:n]
spam.PCA<-cbind(X,spam$spam)
spam.PCA<-as.data.frame(spam.PCA)
colnames(spam.PCA)[dim(spam.PCA)[2]]<-'spam'
spam.PCA$spam<-as.factor(spam.PCA$spam)
levels(spam.PCA$spam)<-c('email','spam')
@


<<red_zad_klasyf, echo=TRUE, eval=TRUE>>=
smp<- sample(dim(spam.PCA)[1],dim(spam.PCA)[1]*0.2)
test <-spam.PCA[smp,]
train<-spam.PCA[-smp,]
task<-makeClassifTask(data=train, target = "spam")
@

\subsection{Regresja Logistyczna}
<<red_RL, echo=FALSE, eval=TRUE, warning=FALSE>>=
logistic.learner <- makeLearner("classif.logreg",predict.type = "prob")
cv.logistic <- crossval(learner = logistic.learner, task = task, iters = 5,
                        stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.logistic$aggr
@

<<red_RL_ROC, echo=FALSE, eval=TRUE, fig.cap="RL po PCA: krzywa ROC", warning=FALSE>>=
ROC(cv.logistic$pred$data[,4],cv.logistic$pred$data[,2])
@

<<red_RL_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ RL po PCA", warning=FALSE>>=
plotLearnerPrediction(learner = logistic.learner, task = task)
@

\subsection{LDA}
<<red_lda, echo=FALSE, eval=TRUE>>=
lda.learner <- makeLearner("classif.lda",predict.type = "prob")
cv.lda <- crossval(learner = lda.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc,tpr,tnr),show.info = F)
cv.lda$aggr
@

<<red_lda_roc, echo=FALSE,eval=TRUE, fig.cap="LDA po PCA: krzywa ROC">>=
ROC(cv.lda$pred$data[,4],cv.lda$pred$data[,2])
@

<<red_lda_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ LDA po PCA">>=
plotLearnerPrediction(learner = lda.learner, task = task)
@

\subsection{Klasyfikator Naiwny Bayesa}
<<red_knb, echo=FALSE, eval=TRUE>>=
bayes.learner <- makeLearner("classif.naiveBayes", predict.type = 'prob')
cv.bayes <- crossval(learner = bayes.learner, task = task,iters = 5,stratif=TRUE,measures = list(acc,mlr::auc,tpr,tnr),show.info = F)
cv.bayes$aggr
@

<<red_knb_roc, echo=FALSE, eval=TRUE, fig.cap="KNB po PCA: krzywa ROC">>=
ROC(cv.bayes$pred$data[,4],cv.bayes$pred$data[,2])
@

<<red_knb_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikator Naiwny Bayes'a po PCA">>=
plotLearnerPrediction(learner = bayes.learner, task = task)
@

\subsection{Metoda k-Najbli¿szych S¹siadów}
<<red_knn, echo=FALSE, eval=TRUE>>=
knn_params <- makeParamSet(
  makeDiscreteParam("k", values = c(1,2,3,4,5,6,7,8,9,10))
)
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.kknn", task = task, resampling = rdesc,
  par.set = knn_params, control = ctrl)
knn.learner <- makeLearner("classif.kknn", predict.type = 'prob', par.vals = tuned_params$x)
cv.knn <- crossval(learner = knn.learner, task = task, iters = 5, 
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.knn$aggr
@


<<>>=
mod <- train(knn.learner, task= task)
test.pred<-predict(mod,newdata = test)
knn.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
knn.test.acc
@

<<red_knn_roc, echo=FALSE, eval=TRUE, fig.cap="kNN po PCA: krzywa ROC">>=
ROC(cv.knn$pred$data[,4],cv.knn$pred$data[,2])
@

<<red_knn_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ kNN po PCA">>=
plotLearnerPrediction(learner = knn.learner, task = task)
@


\subsection{Lasy losowe}
<<red_LL, echo=FALSE, eval=TRUE, warning=FALSE>>=
randForest_params <- makeParamSet(
  makeIntegerParam("ntree", lower = 100, upper = 500),
  makeIntegerParam("mtry", lower = 1, upper = 10),
  makeIntegerParam("maxnodes", lower = 5, upper = 50),
  makeIntegerParam("nodesize", lower = 1, upper = 15)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.randomForest", task = task, resampling = rdesc,
  par.set = randForest_params, control = ctrl)
randForest.learner <- makeLearner("classif.randomForest", predict.type = 'prob', par.vals = tuned_params$x)
cv.randForest <- crossval(learner = randForest.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.randForest$aggr
@

<<warning=FALSE>>=
mod <- train(randForest.learner, task= task)
test.pred<-predict(mod,newdata = test)
randForest.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
randForest.test.acc
@

<<red_RF_ROC, echo=FALSE, eval=TRUE, fig.cap="RF po PCA: krzywa ROC">>=
ROC(cv.randForest$pred$data[,4],cv.randForest$pred$data[,2])
@

<<red_RF_klas, echo=FALSE, eval=TRUE, fig.cap="Las losowy po PCA">>=
plotLearnerPrediction(learner = randForest.learner, task = task)
@

\subsection{Maszyna wektorów noœnych}
<<red_svm, echo=FALSE, eval=TRUE>>=
svm_params <- makeParamSet(
  makeNumericParam("C", lower = -1, upper = 10, trafo = function(x) 2^x),
  makeNumericParam("epsilon", lower = -1, upper = 10, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 10)
rdesc = makeResampleDesc("CV", iters = 3L)
tuned_params = tuneParams("classif.ksvm", task = task, resampling = rdesc,
  par.set = svm_params, control = ctrl)
svm.learner <- setHyperPars(makeLearner("classif.ksvm", predict.type = 'prob'), par.vals = tuned_params$x)
cv.svm <- crossval(learner = svm.learner, task = task, iters = 5,
                   stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.svm$aggr
@


<<echo=FALSE>>=
mod <- train(svm.learner, task= task)
test.pred<-predict(mod,newdata = test)
svm.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
svm.test.acc
@

<<red_svm_roc, echo=FALSE, eval=TRUE, fig.cap="SVM po PCA: krzywa ROC">>=
ROC(cv.svm$pred$data[,4],cv.svm$pred$data[,2])
@

<<red_svm_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ SVM po PCA">>=
plotLearnerPrediction(learner = svm.learner, task = task)
@
\subsection{XGBoost}
<<echo=FALSE>>=
xgb_params <- makeParamSet(
  makeIntegerParam("nrounds", lower = 100, upper = 500),
  makeIntegerParam("max_depth", lower = 1, upper = 10),
  makeNumericParam("eta", lower = .1, upper = .5),
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)
control <- makeTuneControlRandom(maxit = 10)
resample_desc <- makeResampleDesc("CV", iters = 5)
tuned_params <- tuneParams('classif.xgboost', task = task,resampling = resample_desc,par.set = xgb_params,
control = control)
xgboost.learner <- makeLearner("classif.xgboost", predict.type = 'prob', par.vals = tuned_params$x)
cv.xgboost <- crossval(learner = xgboost.learner, task = task, iters = 5,
                          stratif=TRUE, measures = list(acc,mlr::auc,tpr,tnr), show.info = F)
cv.xgboost$aggr
@

<<echo=FALSE>>=
mod <- train(xgboost.learner, task= task)
test.pred<-predict(mod,newdata = test)
xgboost.test.acc<-mean(test.pred$data[,1]==test.pred$data[,4])
xgboost.test.acc
@

<<echo=FALSE, eval=TRUE, fig.cap="XGBoost: krzywa ROC">>=
ROC(cv.xgboost$pred$data[,4],cv.xgboost$pred$data[,2])
@

<<red_xgb_klas, echo=FALSE, eval=TRUE, fig.cap="Klasyfikacja metod¹ SVM po PCA">>=
plotLearnerPrediction(learner = xgboost.learner, task = task)
@

\subsection{Porównanie}
<<red_por_klas, echo=FALSE, eval=TRUE, results='asis', fig.cap="Porównanie klasyfikatorów (po PCA)">>=
wyniki<-rbind(cv.logistic$aggr,cv.lda$aggr,cv.bayes$aggr,cv.knn$aggr,cv.randForest$aggr,cv.svm$aggr,cv.xgboost$aggr)
wyniki<-as.data.frame(wyniki)
rownames(wyniki)<-c('Regresja Logistyczna','LDA','Naiwny Bayes','kNN','Lasy Losowe','Maszyna Wektorów Noœnych','XGBoost')
colnames(wyniki)<-c('Skutecznoœæ','AUC','Czu³oœæ','Specyficznoœæ')
xtab<-xtable(wyniki, caption = 'Porównanie skutecznoœci metod klasyfikacji dla sk³adowych g³ównych danych "spam" ')
print(xtab)
@
Tym razem wyraŸniej widaæ przewagê z³o¿onoœci algorytmu XGBoost nad prostrzymi metodami np. Regresji Logistycznej. Skutecznoœæ metody LDA wyraŸnie spad³a, natomiast pozosta³e metody zaliczy³y oko³o 4-5\% spadek skutecznoœci. 
<<red_pred, echo=FALSE, eval=TRUE>>=
pred.logistic<-getRRPredictions(cv.logistic)
pred.lda<-getRRPredictions(cv.lda)
pred.bayes<-getRRPredictions(cv.bayes)
pred.knn<-getRRPredictions(cv.knn)
pred.randForest<-getRRPredictions(cv.randForest)
pred.svm<-getRRPredictions(cv.svm)
pred.xgboost<-getRRPredictions(cv.xgboost)
@
Poni¿ej przedstawiono porównanie krzywych ROC dla wszystkich klasyfikatorów:
<<red_por_roc, echo=FALSE, eval=TRUE, fig.cap="Porównanie krzywych ROC dla ró¿nych klasyfikatorów (po PCA)">>=
df = generateThreshVsPerfData(list(lda = pred.lda, logistic=pred.logistic, bayes=pred.bayes,knn=pred.knn,randForest=pred.randForest,svm = pred.svm, xgboost=pred.xgboost), measures = list(fpr, tpr))
ggplot(as.data.frame(df$data),aes(x=fpr,y=tpr, col=learner))+geom_line()
@

Podobnie tym razem, bazuj¹c na mierze dok³adnoœci i auc, mo¿emy stwierdziæ, ¿e najlepiej poradzi³a sobie metoda lasów losowych.

\section{Analiza skupieñ}
Za³ó¿my na chwilê, ¿e nie wiemy jak sklasyfikowane s¹ obserwacje, którymi dysponujemy, tzn. nie wiemy czy s¹ spamem, czy nie. Usuwamy z danych kolumnê typu factor, wskazuj¹c¹ na ten podzia³. Wykorzystamy poznane metody klasteryzacji, maj¹ce na celu grupowanie danych w skupienia obiektów jak najbardziej do siebie podobnych, co wi¹¿e siê z rozpoznaniem struktury danych. Rozwa¿ymy metody grupuj¹ce, jak np. k-means i PAM oraz metody chierarchiczne, tj. AGNES i DIANA. Na koniec ocenimy jakoœæ grupowania.
%\subsection{Analiza skupieñ z mlrem}
<<zad_cluster, echo=FALSE, eval=FALSE>>=
cluster.task <- makeClusterTask(data = spam)
cluster.task
library(clue)
cluster.lrn = makeLearner("cluster.kmeans", centers = 5)
cluster.lrn$par.vals
@

\subsection{Metody grupuj¹ce}
Zaczniemy od metody k-means i podziale na dwa klastry.
<<start_an_sk, echo=FALSE, eval=TRUE, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ k-means (w przek³adowej przestrzeni dwóch zmiennych)">>=

spam.cechy <- spam[,1:57] # Usuwamy etykietki klas
spam.etykietki.rzeczywiste <- spam[,58]

k <- 2
kmeans.k2 <- kmeans(spam.cechy, centers=k, iter.max=20)
spam.etykietki.kmeans <- kmeans.k2$cluster

# Wizualizacja wyników analizy skupieñ 
plot(spam.cechy$A.55, spam.cechy$A.57, col=spam.etykietki.kmeans,
     pch=as.numeric(spam.etykietki.rzeczywiste))

points( kmeans.k2$centers[,c("A.23","A.6")],pch=16, cex=1.5, col=1:2)

@
Wypróbujemy równie¿ nieco bardziej z³o¿on¹ metodê PAM.
<<pam, echo=FALSE, eval=TRUE, fig.height=4.5, fig.width=6, fig.cap="Wizualizacja wyników analizy skupieñ metod¹ PAM">>=
#PAM
spam.pam<-spam[,1:57]
mac.niepod<-as.matrix(daisy(spam.pam))
spam.pam2 <- pam(x = mac.niepod, diss=TRUE, k=2)
etykietki <- spam.pam2$clustering
plot(spam.pam2, col=etykietki, metric="euclidian")

# summary(spam.pam2)
#  rozmiar(size), maksymalna i œrednia wartoœæ niepodobieñstwa (max_diss,av_diss),
#  œrednica (diameter), separacja  (separation)
# które obiekty s¹ centrami skupisk : CentraSkupisk.nazwy <- Cars93.pam3$medoids
@
Obserwuj¹c powy¿szy wykres mo¿emy zaobserwowaæ, ¿e otrzymaliœmy skupienia, o wyraŸnie ró¿nych liczbach obserwacji. Przypomnijmy, ¿e nasz zbiór sk³ada siê w ok. 60 \% z maili i ok. 40\% ze spamu, dlatego tak nierówne klastry, jakie otrzymaliœmy za pomoc¹ metody PAM, na pierwszy rzut oka, wydaj¹ siê nieodpowiednie. Z ³atwoœci¹, mo¿emy równie¿ narysowaæ wykres klastrów, w przestrzeni dwóch pierwszych sk³adowych g³ównych otrzymanych za pomoc¹ PCA.
<<clusplot, echo=FALSE, eval=TRUE, fig.cap="Wizualizacja wyników analizy skupieñ z wykorzystaniem PCA">>=
spam.CechyLiczbowe <- spam[,names(unlist(lapply(spam, FUN=function(x) if(is.numeric(x)) "numeric" else NULL)))]
spam.numeric.pam2 <- pam(spam.CechyLiczbowe, k=2, metric="euclidean")

clusplot(spam.numeric.pam2, color=FALSE, col.clus="yellow", col.p="red", plotchar=TRUE, shade=TRUE) #clusplot, z PCA

#jeszcze nie wiem jak oprócz kszta³tów rozró¿niæ kolory miêdzy klastrami :()
@
Przejdziemy teraz do drugiej grupy metod analizy skupieñ.
\subsection{Metody chierarchiczne}
W przypadku metod chierarchicznych, rozwa¿ymy dwa warianty: metodê aglomeracyjn¹ AGNES i metodê rozdzielania DIANA. Wyniki spróbujemy zwizualizowaæ za pomoc¹ wykresów typu 'bannerplot', dendrogramy w przypadku tak du¿ej iloœci danych, s¹ ca³kowicie nieczytelne.
<<AS_chierarch, echo=FALSE, eval=TRUE, fig.cap="AGNES: wykres typu 'banner'">>=
spam.scale<-scale(spam[,1:57])
spam.MacNiepodob<-daisy(spam.scale) #przygotowujemy macierz podobieñstw/odmiennosci
spam.agnes.avg <- agnes(x=spam.MacNiepodob,diss=TRUE,method="average") #wykorzystujemy optymaln¹ metodê  average linkage
#spam.agnes.single <- agnes(x=spam.MacNiepodob,diss=TRUE,method="single")
#spam.agnes.complete <- agnes(x=spam.MacNiepodob,diss=TRUE,method="complete")

plot(spam.agnes.avg, which.plot=1, main="AGNES: average linkage")
#zbyt wiele zmiennych, ¿eby wykres by³ czytelny

#plot(spam.agnes.single,which.plots=2,main="AGNES: single linkage")
#plot(spam.agnes.complete,which.plots=2, main="AGNES: complete linkage") agl_coeff = 0.97

spam.agnes.avg.k2 <- cutree(spam.agnes.avg, k=2) #odcinanie klastróW
sil.agnes <- silhouette(x=spam.agnes.avg.k2, dist=spam.MacNiepodob) #wsk. silhouette

@
Ostani¹ metod¹ analizy skupieñ jak¹ rozwa¿ymy bêdzie metoda DIANA, jest to metoda rozdzielaj¹ca, nale¿¹ca do grupy metod aglomeracyjnych.

<<AS_diana, echo=FALSE, eval=TRUE, fig.cap="DIANA: wykres typu 'banner'">>=
spam.diana <- diana(x=spam.MacNiepodob,diss=TRUE)

plot(spam.diana, which.plot=1, main="DIANA")

spam.diana.k2 <- cutree(spam.diana, k=2)
sil.diana <-silhouette(x=spam.diana.k2, dist=spam.MacNiepodob)

@
Obserwuj¹c dwa powy¿sze wykresy, nie trudno zauwa¿yæ, ¿e wyci¹gniêcie sensownych wniosków jest niemal¿e niemo¿liwe. W zwi¹zku z tym, maj¹c na uwadze chêæ wizualizacji wyników, w dalszych analizach rozwa¿ymy analizê skupieñ wybranego w sposób losowy ze zbioru danych "spam", podzbioru.
%\subsection{Ocena jakoœci grupowania}
%Ostatnim krokiem analizy skupieñ bêdzie ocena jakoœci grupowania. W celu oceny, w jakim stopniu odkryte przez algorytm %kupienia #odpowiadaj¹ rzeczywistej strukturze danych, wykorzystamy zarówno wskaŸniki wewnêtrzne, jak i zewnêtrzne.

<<zgodnosc_partycji, echo=FALSE, eval=FALSE>>=
library(e1071)

# porównanie wynikow grupowania z rzeczywist¹ przynaleznoscia do klas
tab.spam.kmeans <- table(kmeans.k2$clustering, spam$spam)
tab.spam.kmeans
matchClasses(tab.spam.kmeans, method="exact")

tab.spam.pam <- table(spam.pam2$clustering, spam$spam)
tab.spam.pam
matchClasses(tab.spam.pam, method="exact")

tab.spam.agnes <- table(spam.agnes.avg.k2, spam$spam)
tab.spam.agnes
matchClasses(tab.spam.agnes, method="exact")

tab.spam.diana <- table(spam.diana.k2, spam$spam)
tab.spam.diana
matchClasses(tab.spam.diana, method="exact")

tab.pam.agnes <- table(spam.pam2$clustering, spam.agnes.avg.k2)
tab.pam.agnes
matchClasses(tab.pam.agnes, method="exact")


@



\section{*Analiza skupieñ podzbioru danych "spam"}
W zwi¹zku z trudnoœciami w wizualizacji wyników analizy skupieñ na zbiorze danych zawieraj¹cym a¿ 4601 obserwacji, postanowiliœmy przeprowadziæ i zwizualizowaæ podobne analizy po wylosowaniu 100 elementowego podzbioru danych "spam".

<<AS_los, echo=FALSE, eval=TRUE>>=
n<-dim(spam)[1]
set.seed(123)
los.indeksy<-sample(1:n, 100)
los.podzb<-spam[los.indeksy,]
y_podzb<-los.podzb[,dim(los.podzb)[2]]
table(y_podzb) #stosunek e_maili do spamu podobny jak w ca³ej próbce
@
\subsection{Metody grupuj¹ce}
Zaczynamy, podobnie jak wczeœniej od metody k-means.
<<AS_grup, echo=FALSE, eval=TRUE, fog.height=4, fig.width=6, fig.cap="Wizualizacja (w przestrzeni dwóch przyk³adowych zmiennych) wyników analizy skupieñ pozdbioru 100 elementowego">>=
spamlos.cechy <- los.podzb[,1:57] # Usuwamy etykietki klas
spamlos.etykietki.rzeczywiste <- los.podzb[,58]

k <- 2
kmeans.k2 <- kmeans(spamlos.cechy, centers=k, iter.max=20)
spamlos.etykietki.kmeans <- kmeans.k2$cluster

# Wizualizacja wyników analizy skupieñ 
plot(spamlos.cechy$A.26, spamlos.cechy$A.57, col=spamlos.etykietki.kmeans,
     pch=as.numeric(spamlos.etykietki.rzeczywiste))

points( kmeans.k2$centers[,c("A.23","A.6")],pch=16, cex=1.5, col=1:2)
@
Nastêpnie wykorzystujemy metodê PAM.
<<AS_grup2, echo=FALSE,eval=TRUE, fig.height=4, fig.width=6, warnings=FALSE, fig.cap="Analiza skupieñ metod¹ PAM - podzbiór 100 elementowy">>=
#################################3
spamlos.pam<-los.podzb[,1:57]
mac.niepod<-as.matrix(daisy(spamlos.pam))
spamlos.pam2 <- pam(x = mac.niepod, diss=TRUE, k=2)
etykietki <- spamlos.pam2$clustering
plot(spamlos.pam2, col=etykietki, metric="euclidian")

spamlos.CechyLiczbowe <- los.podzb[,names(unlist(lapply(los.podzb, FUN=function(x) if(is.numeric(x)) "numeric" else NULL)))]
spamlos.numeric.pam2 <- pam(spamlos.CechyLiczbowe, k=2, metric="euclidean")

#clusplot(spamlos.numeric.pam2, col.clus="yellow", col.p="red", plotchar=TRUE, shade=TRUE) #clusplot, z PCA
@

\subsection{Metody chierarchiczne}
Poni¿ej prezentujemy wykresy dendrogramu (metoda average linkage) i banerowy w przypadku metody aglomeracyjnej AGNES.
<<AS_chierarch_agnes, echo=FALSE, eval=TRUE, fig.height=10, fig.width=8, fig.cap="Metody chierarchiczne: AGNES">>=
spamlos.scale<-scale(los.podzb[,1:57])
spamlos.MacNiepodob<-daisy(spamlos.scale) #przygotowujemy macierz podobieñstw/odmiennosci
spamlos.agnes.avg <- agnes(x=spamlos.MacNiepodob,diss=TRUE,method="average") #wykorzystujemy optymaln¹
par(mfrow=c(2,1))
plot(spamlos.agnes.avg, which.plot=1, main="AGNES: average linkage")
plot(spamlos.agnes.avg, which.plot=2, main="AGNES: average linkage")
par(mfrow=c(1,1))

spamlos.agnes.avg.k2 <- cutree(spamlos.agnes.avg, k=2) #odcinanie klastróW
sil.agnes <- silhouette(x=spamlos.agnes.avg.k2, dist=spamlos.MacNiepodob) #wsk. silhouette
@
Nastêpnie przedstawiamy wizualizacjê wyników klasteryzacji metod¹ DIANA.
<<AS_chierarch_diana, echo=FALSE, eval=TRUE, fig.height=10, fig.width=8, fig.cap="Metody chierarchiczne: DIANA">>=
############################ DIANA
spamlos.diana <- diana(x=spamlos.MacNiepodob,diss=TRUE)

par(mfrow=c(2,1))
plot(spamlos.diana, which.plot=1, main="DIANA")
plot(spamlos.diana, which.plot=2, main="DIANA")
par(mfrow=c(1,1))

spamlos.diana.avg.k2 <- cutree(spamlos.diana, k=2)
sillos.diana <-silhouette(x=spamlos.diana.avg.k2, dist=spamlos.MacNiepodob)

@
Na koniec, mo¿emy przejœæ do oceny jakoœci grupowania.
\subsection{Analiza jakoœci grupowania}
Jakoœæ grupowania ocenimy posi³kuj¹c siê kilkoma wskaŸnikami wewnêtrznymi i zewnêtrznymi.

\subsubsection{WskaŸniki wewnêtrzne}
Poni¿ej prezentujemy wartoœci wskaŸników zewnêtrznych takich jak Connectivity, wskaŸnik Dunna i Silhouette dla ró¿nych modeli klasteryzacji, dla liczby klastrów od 2 do 6.
<<tot_wsk_wew, echo=FALSE, eval=TRUE, warning=FALSE>>=
wsk.wew <- clValid(los.podzb[,1:57], nClust=2:6, validation = "internal",
                               clMethods = c("hierarchical","kmeans","diana", 
                                             "fanny", "pam", "clara","model"))
                               
summary(wsk.wew)
#optimalScores(wsk.wew)
@
W sekcji "Optimal Scores", otrzymujemy listê metod (wraz z liczb¹ klastrów), które wed³ug poszczególnych wskaŸników okaza³y siê byæ najlepsze. W naszym przypadku, wg wszystkich wskaŸników, najlepsza okaza³a siê byæ metoda hierarchiczna z dwoma klastrami (Connectivity, Silhouette) lub czterema (wskaŸnik Dunna).
Zbadaliœmy te¿ stabilnoœæ.
<<tot_wsk_wew_stab, echo=FALSE, eval=TRUE,warning=FALSE>>=
#### STABILNOŒÆ ###
wsk.stab <- clValid(los.podzb[,1:57],nClust=2:6, validation = "stability",
                    clMethods = c("hierarchical","kmeans", "diana", 
                                  "pam", "clara","model"))
summary(wsk.stab)
#optimalScores(wsk.stab)
@
Pod wzglêdem stabilnoœci, bazuj¹c na wskaŸnikach APN i ADM, najlepiej wypad³a metoda kmeans (2 klastry) a bazuj¹c na AD - metoda pam (6 klastrów).

\subsection{WskaŸniki zewnêtrzne} 
Na koniec przejdziemy do analizy wskaŸników zewnêtrznych, czyli wykorzystania informacji o rzeczywistej przynale¿noœci do klas. 
<<podzb_wsk_zew, echo=FALSE, eval=TRUE>>=
#wsk_zewn
# porównanie wynikow grupowania z rzeczywist¹ przynaleznoscia do klas
print("kmeans")
tab.kmeans <- table(kmeans.k2$cluster, los.podzb$spam)
matchClasses(tab.kmeans, method="exact")

print("pam")
tab.pam <- table(spamlos.pam2$clustering, los.podzb$spam)
matchClasses(tab.pam, method="exact")

print("agnes")
tab.spamlos.agnes <- table(spamlos.agnes.avg.k2,los.podzb$spam)
matchClasses(tab.spamlos.agnes, method="exact")


tab.kmeans.pam <- table(kmeans.k2$cluster, spamlos.pam2$clustering)
tab.kmeans.agnes <-table(kmeans.k2$cluster, spamlos.agnes.avg.k2)

print("kmeans_pam")
matchClasses(tab.kmeans.pam, method="exact")
print("kmeans_agnes")
matchClasses(tab.kmeans.agnes, method="exact")

@
Z powy¿szej analizy wynika, ¿e w przypadku kmeans 68\% obserwacji jest sklasyfikowana tak samo jak w rzeczywistoœci, dla PAM 64\%, a metoda AGNES dostarcza 62\% zgodnoœci. Przy wzajemnym porównaniu, uzyskujemy, ¿e kmeans i pam przyporz¹dkowuj¹ podobnie 98\% obiektów, a kmeans i agnes 94\%.

\section{Podsumowanie}
Wkrótce


\end{document}